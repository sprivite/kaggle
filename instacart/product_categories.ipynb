{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from math import factorial\n",
    "import pylab\n",
    "pylab.rcParams['figure.figsize'] = (10, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "#\n",
    "# This is a continuation of the data exploration started in summary_all.ipynb. The first\n",
    "# notebook considered the data on the largest scale, aggregating all customers together.\n",
    "# We now want to understand exactly what the customer data looks like to get a sense of how\n",
    "# we can use it to make predictions.\n",
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   order_id  user_id eval_set  order_number  order_dow  order_hour_of_day  \\\n",
      "0    375303       30    prior             1          1                 13   \n",
      "1    375303       30    prior             1          1                 13   \n",
      "2    375303       30    prior             1          1                 13   \n",
      "3   2156000       30    prior             2          1                 10   \n",
      "4   3169631       30    prior             3          1                 22   \n",
      "\n",
      "   days_since_prior_order  product_id  add_to_cart_order  reordered  \\\n",
      "0                     NaN     21386.0                1.0        0.0   \n",
      "1                     NaN     27839.0                2.0        0.0   \n",
      "2                     NaN     45128.0                3.0        0.0   \n",
      "3                     7.0     21386.0                1.0        1.0   \n",
      "4                     7.0     21386.0                1.0        1.0   \n",
      "\n",
      "                         product_name  aisle_id  department_id department  \n",
      "0                          Smartwater     115.0            7.0  beverages  \n",
      "1  49 Flavors Jelly Belly Jelly Beans      45.0           19.0     snacks  \n",
      "2                 Milk Chocolate M&Ms      45.0           19.0     snacks  \n",
      "3                          Smartwater     115.0            7.0  beverages  \n",
      "4                          Smartwater     115.0            7.0  beverages  \n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# We throw away a small fraction of the training data for an exploratory playground\n",
    "#\n",
    "N = 10000 # full training set is 75000\n",
    "train = pd.read_csv('order_products__train.csv')\n",
    "oids = train['order_id'].unique()[:N]\n",
    "\n",
    "#print train.groupby('order_id').get_group(1)\n",
    "train = train[train['order_id'].isin(oids)]\n",
    "#print train.groupby('order_id').get_group(1)\n",
    "\n",
    "# get the corresponding users ids\n",
    "orders = pd.read_csv('orders.csv')\n",
    "uids = orders[orders['order_id'].isin(oids)]['user_id']\n",
    "assert len(uids) == len(oids)\n",
    "\n",
    "orders = orders[orders['user_id'].isin(uids)]\n",
    "\n",
    "# now get the products contained in these orders\n",
    "products = orders.merge(pd.read_csv('order_products__prior.csv'), on='order_id', how='left')\n",
    "products = products.merge(pd.read_csv('products.csv'), on='product_id', how='left')\n",
    "products = products.merge(pd.read_csv('departments.csv'), on='department_id', how='left')\n",
    "\n",
    "print products.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "department\n",
      "personal care      0.315587\n",
      "pantry             0.348234\n",
      "international      0.366351\n",
      "other              0.389417\n",
      "household          0.402363\n",
      "missing            0.408463\n",
      "canned goods       0.462662\n",
      "dry goods pasta    0.465326\n",
      "frozen             0.544682\n",
      "breakfast          0.552753\n",
      "babies             0.572886\n",
      "snacks             0.572935\n",
      "meat seafood       0.574865\n",
      "alcohol            0.586011\n",
      "bulk               0.610356\n",
      "deli               0.614684\n",
      "bakery             0.625252\n",
      "pets               0.628368\n",
      "beverages          0.652905\n",
      "produce            0.653538\n",
      "dairy eggs         0.672758\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Let's get crazy. Let our hair down a bit ...\n",
    "#\n",
    "x = products.groupby('department').apply(lambda x: sum(x['reordered']) / len(x))\n",
    "print x.sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Not surprising. The kind of product it is correlates to its \"repurchasedness\".\n",
    "# We should include department_id as a feature in the next step. It's maybe not clear\n",
    "# whether this contains *new* information. \n",
    "#"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
