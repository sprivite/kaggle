{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from collections import Counter\n",
    "from evaluate import f1score\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading and merging orders tables ...  done.\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Read in training (and validation) data\n",
    "# \n",
    "\n",
    "print \"Reading and merging orders tables ... \",\n",
    "\n",
    "train = pd.read_csv('order_products__train.csv')\n",
    "prior = pd.read_csv('order_products__prior.csv')\n",
    "orders = pd.read_csv('orders.csv')\n",
    "products = pd.read_csv('products.csv')\n",
    "\n",
    "train = train.merge(\n",
    "    orders, on='order_id', how='left').merge(\n",
    "    products, on='product_id', how='left')\n",
    "prior = prior.merge(orders, on='order_id', how='left').merge(\n",
    "    products, on='product_id', how='left')\n",
    "\n",
    "# compute training target\n",
    "target = train.groupby('user_id'\n",
    "    ).apply(lambda x: set(x[x['reordered'] == True]['product_id'])\n",
    "    ).reset_index(name='target')\n",
    "\n",
    "print \"done.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing product features ...  done.\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Before splitting off the validation set, compute \"product features\".\n",
    "# These are features that depend only on product_id; their values are the\n",
    "# same for training, validation and testing.\n",
    "#\n",
    "\n",
    "print \"Computing product features ... \",\n",
    "\n",
    "#   number of users who ever had this product in their basket\n",
    "x = prior.groupby('product_id').apply(\n",
    "    lambda x: len(set(x['user_id']))).reset_index(name='nusers')\n",
    "\n",
    "# number of users that reorderd the item\n",
    "y = train.groupby('product_id').apply(\n",
    "    lambda x: x['reordered'].sum()).reset_index(name='reordered')\n",
    "\n",
    "reorder_prob = x.merge(y, on='product_id', how='left').fillna(0)\n",
    "reorder_prob['reorder_prob'] = reorder_prob['reordered'] / reorder_prob['nusers']\n",
    "del x, y, reorder_prob['reordered'], reorder_prob['nusers']\n",
    "\n",
    "print \"done.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing user / user-product features ... \n",
      "\tnorders of product by user ... \n",
      "\tnorders by user\n",
      "\tbaskets since last order of product ...\n",
      "\thow often the product appears in the same user's basket ... done.\n"
     ]
    }
   ],
   "source": [
    "# Generate np array of features ...\n",
    "#\n",
    "# We will use as features:\n",
    "#\n",
    "\n",
    "print \"Computing user / user-product features ... \"\n",
    "\n",
    "prior_gb_up = prior.groupby(['user_id', 'product_id'])\n",
    "\n",
    "#   1: Number of times product has been ordered by user\n",
    "print \"\\tnorders of product by user ... \"\n",
    "user_prod_norders = prior_gb_up.apply(len).reset_index(name='user_prod_norders')\n",
    "\n",
    "#   2: Total number of orders by user\n",
    "print \"\\tnorders by user\"\n",
    "user_norders = prior.groupby('user_id'\n",
    "    ).apply(lambda x: len(set(x['order_id']))).reset_index(name='user_norders')\n",
    "# FIXME is there a way to reuse prior_gb_up here? \n",
    "\n",
    "#   3: Number of baskets since user last ordered this item\n",
    "print \"\\tbaskets since last order of product ...\"\n",
    "baskets_since = prior_gb_up.apply(\n",
    "    lambda x: max(x['order_number'])).reset_index(name='last_basket')\n",
    "\n",
    "baskets_since = baskets_since.merge(user_norders, on='user_id', how='left')\n",
    "baskets_since['basktets_since'] = baskets_since['user_norders'] - baskets_since['last_basket']\n",
    "del baskets_since['user_norders'], baskets_since['last_basket']\n",
    "del prior_gb_up\n",
    "\n",
    "#   4: Number of times product has been ordered / number of users that\n",
    "#      that have ordered the product\n",
    "print \"\\thow often the product appears in the same user's basket ...\",\n",
    "reorder_rate = prior.groupby('product_id').apply(\n",
    "    lambda x: float(len(x)) / float(len(set(x['user_id'])))\n",
    "    ).reset_index(name='reorder_rate')\n",
    "\n",
    "print \"done.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>user_prod_norders</th>\n",
       "      <th>user_norders</th>\n",
       "      <th>basktets_since</th>\n",
       "      <th>reorder_rate</th>\n",
       "      <th>reorder_prob</th>\n",
       "      <th>reordered</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>196</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>4.473875</td>\n",
       "      <td>0.152625</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>10258</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>3.493716</td>\n",
       "      <td>0.140036</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>10326</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>2.873635</td>\n",
       "      <td>0.147166</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>12427</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>3.857058</td>\n",
       "      <td>0.095295</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>13032</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>2.916796</td>\n",
       "      <td>0.090202</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>13176</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>5.972111</td>\n",
       "      <td>0.210303</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>14084</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>5.290505</td>\n",
       "      <td>0.148406</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>17122</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>3.082390</td>\n",
       "      <td>0.104819</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>25133</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>3.848447</td>\n",
       "      <td>0.086335</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>26088</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>2.169390</td>\n",
       "      <td>0.066208</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>26405</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>1.790560</td>\n",
       "      <td>0.091445</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>30450</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>2.307775</td>\n",
       "      <td>0.052191</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>35951</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>4.129458</td>\n",
       "      <td>0.120043</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>38928</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>5.806140</td>\n",
       "      <td>0.144298</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>39657</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>4.278772</td>\n",
       "      <td>0.177323</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    user_id  product_id  user_prod_norders  user_norders  basktets_since  \\\n",
       "0         1         196                 10            10               0   \n",
       "1         1       10258                  9            10               0   \n",
       "2         1       10326                  1            10               5   \n",
       "3         1       12427                 10            10               0   \n",
       "4         1       13032                  3            10               0   \n",
       "5         1       13176                  2            10               5   \n",
       "6         1       14084                  1            10               9   \n",
       "7         1       17122                  1            10               5   \n",
       "8         1       25133                  8            10               0   \n",
       "9         1       26088                  2            10               8   \n",
       "10        1       26405                  2            10               6   \n",
       "11        1       30450                  1            10               7   \n",
       "12        1       35951                  1            10               0   \n",
       "13        1       38928                  1            10               0   \n",
       "14        1       39657                  1            10               0   \n",
       "\n",
       "    reorder_rate  reorder_prob  reordered  \n",
       "0       4.473875      0.152625        1.0  \n",
       "1       3.493716      0.140036        1.0  \n",
       "2       2.873635      0.147166        0.0  \n",
       "3       3.857058      0.095295        0.0  \n",
       "4       2.916796      0.090202        1.0  \n",
       "5       5.972111      0.210303        0.0  \n",
       "6       5.290505      0.148406        0.0  \n",
       "7       3.082390      0.104819        0.0  \n",
       "8       3.848447      0.086335        1.0  \n",
       "9       2.169390      0.066208        1.0  \n",
       "10      1.790560      0.091445        1.0  \n",
       "11      2.307775      0.052191        0.0  \n",
       "12      4.129458      0.120043        0.0  \n",
       "13      5.806140      0.144298        1.0  \n",
       "14      4.278772      0.177323        1.0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "# Assemble all features together in one table\n",
    "#\n",
    "features = user_prod_norders.merge(\n",
    "    user_norders, on='user_id', how='left'\n",
    "    ).merge(baskets_since, on=['user_id', 'product_id'], how='left'\n",
    "    ).merge(reorder_rate, on='product_id', how='left'\n",
    "    ).merge(reorder_prob, on='product_id', how='left')\n",
    "del user_norders, baskets_since, reorder_rate\n",
    "# need to keep \"product features\" for submission stage\n",
    "\n",
    "# Add training data, i.e., whether product was reordered by user\n",
    "features = features.merge(\n",
    "    train[['user_id','product_id','reordered']],\n",
    "    on=['user_id','product_id'], how='left').fillna(0)\n",
    "\n",
    "features.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000 81209 75000 206209\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Establish separate training and validation data\n",
    "#\n",
    "\n",
    "Nval = 50000 # seems like a good number\n",
    "uids = train['user_id'].unique()\n",
    "uids_train = uids[:-Nval]\n",
    "uids_val = uids[-Nval:]\n",
    "\n",
    "#\n",
    "# training\n",
    "#\n",
    "where = features['user_id'].isin(uids_train)\n",
    "X_train = features[where][[\n",
    "    'user_prod_norders',\n",
    "    'user_norders',\n",
    "    'basktets_since',\n",
    "    'reorder_rate',\n",
    "    'reorder_prob']].as_matrix()\n",
    "y_train = features[where]['reordered'].as_matrix()\n",
    "\n",
    "#\n",
    "# validation\n",
    "#\n",
    "where = features['user_id'].isin(uids_val)\n",
    "X_val = features[where][[\n",
    "    'user_prod_norders',\n",
    "    'user_norders',\n",
    "    'basktets_since',\n",
    "    'reorder_rate',\n",
    "    'reorder_prob']].as_matrix()\n",
    "y_val = features[where]['reordered'].as_matrix()\n",
    "\n",
    "#\n",
    "# test / submission\n",
    "#\n",
    "uids_test = orders[orders['eval_set'] == 'test']['user_id'].unique()\n",
    "where = features['user_id'].isin(uids_test)\n",
    "X_test = features[where][[\n",
    "    'user_prod_norders',\n",
    "    'user_norders',\n",
    "    'basktets_since',\n",
    "    'reorder_rate',\n",
    "    'reorder_prob']].as_matrix()\n",
    "\n",
    "print len(uids_val), len(uids_train), len(uids_test), len(orders['user_id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Train the decision tree model(s)\n",
    "#\n",
    "\n",
    "trees = []\n",
    "clf = AdaBoostClassifier(n_estimators=100)\n",
    "clf.fit(X_train, y_train)\n",
    "trees.append(clf)\n",
    "    #export_graphviz(clf, out_file='tree.dot')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance on training set ... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/local/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.195 0.215111613238\n",
      "Performance on validation set ... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/local/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/ipykernel_launcher.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.195 0.215869912678\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Let's see how we covered the training set\n",
    "#\n",
    "print \"Performance on training set ... \"\n",
    "this_target = target[target['user_id'].isin(uids_train)]\n",
    "this_features = features[features['user_id'].isin(uids_train)]\n",
    "for clf in trees:\n",
    "    pred = clf.predict_proba(X_train)[:, 1]\n",
    "    for p in [0.195]: # time and time again, this value wins\n",
    "        this_features['prediction'] = pred > p\n",
    "        out = this_features.groupby('user_id').apply(\n",
    "            lambda x: set(x[x['prediction'] == True]['product_id'])\n",
    "            ).reset_index(name='prediction')\n",
    "\n",
    "        out = out.merge(this_target, on='user_id', how='left')\n",
    "        print p, f1score(out['prediction'], out['target'])\n",
    "        del this_features['prediction']\n",
    "    \n",
    "#\n",
    "# Now, how do we perform out of sample?\n",
    "#\n",
    "print \"Performance on validation set ... \"\n",
    "this_target = target[target['user_id'].isin(uids_val)]\n",
    "this_features = features[features['user_id'].isin(uids_val)]\n",
    "for clf in trees:\n",
    "    pred = clf.predict_proba(X_val)[:, 1]\n",
    "    for p in [0.195]:\n",
    "        \n",
    "        this_features['prediction'] = pred > p\n",
    "        out = this_features.groupby('user_id').apply(\n",
    "            lambda x: set(x[x['prediction'] == True]['product_id'])\n",
    "            ).reset_index(name='prediction')\n",
    "\n",
    "        out = out.merge(this_target, on='user_id', how='left')\n",
    "        print p, f1score(out['prediction'], out['target'])\n",
    "        del this_features['prediction']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/local/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17</td>\n",
       "      <td>{47766, 13107, 21709, 39275, 21463}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34</td>\n",
       "      <td>{47792, 44632, 39180, 43504, 21137, 16083, 477...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>137</td>\n",
       "      <td>{38689, 25890, 44422, 5134, 23794, 24852, 2326...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>182</td>\n",
       "      <td>{11520, 5479, 33000, 47209, 39275, 41149, 4767...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>257</td>\n",
       "      <td>{27104, 49235, 24838, 39475, 29837, 13870, 211...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   order_id                                         prediction\n",
       "0        17                {47766, 13107, 21709, 39275, 21463}\n",
       "1        34  {47792, 44632, 39180, 43504, 21137, 16083, 477...\n",
       "2       137  {38689, 25890, 44422, 5134, 23794, 24852, 2326...\n",
       "3       182  {11520, 5479, 33000, 47209, 39275, 41149, 4767...\n",
       "4       257  {27104, 49235, 24838, 39475, 29837, 13870, 211..."
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "# Let's make a submission!!\n",
    "#\n",
    "clf = trees[2]\n",
    "\n",
    "#\n",
    "# generate predictions for test set from model\n",
    "#\n",
    "oid_uid_test = orders[orders['eval_set'] == 'test'][['order_id', 'user_id']]\n",
    "pred = clf.predict_proba(X_test)[:, 1] > 0.195\n",
    "this_features = features[features['user_id'].isin(uids_test)]\n",
    "this_features['prediction'] = pred\n",
    "this_features = this_features.merge(oid_uid_test, on='user_id', how='left')\n",
    "out = this_features.groupby('order_id').apply(\n",
    "    lambda x: set(x[x['prediction'] == True]['product_id'])\n",
    "    ).reset_index(name='prediction')\n",
    "\n",
    "out.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Write predictions to disk for submission.\n",
    "#\n",
    "\n",
    "fd = open('submission.csv', 'w')\n",
    "fd.write('order_id,products\\n')\n",
    "\n",
    "for oid, pr in zip(out['order_id'], out['prediction']):\n",
    "    fd.write('%d,' % oid)\n",
    "\n",
    "    if pr:\n",
    "        fd.write(' '.join(map(str, pr)))\n",
    "    else:\n",
    "        fd.write('None')\n",
    "    fd.write('\\n')\n",
    "\n",
    "fd.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
