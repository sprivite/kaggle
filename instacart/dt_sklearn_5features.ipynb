{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from collections import Counter\n",
    "from evaluate import f1score\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading and merging orders tables ...  done.\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Read in training (and validation) data\n",
    "# \n",
    "\n",
    "print \"Reading and merging orders tables ... \",\n",
    "\n",
    "train = pd.read_csv('order_products__train.csv')\n",
    "prior = pd.read_csv('order_products__prior.csv')\n",
    "orders = pd.read_csv('orders.csv')\n",
    "products = pd.read_csv('products.csv')\n",
    "\n",
    "train = train.merge(\n",
    "    orders, on='order_id', how='left').merge(\n",
    "    products, on='product_id', how='left')\n",
    "prior = prior.merge(orders, on='order_id', how='left').merge(\n",
    "    products, on='product_id', how='left')\n",
    "\n",
    "# compute training target\n",
    "target = train.groupby('user_id'\n",
    "    ).apply(lambda x: set(x[x['reordered'] == True]['product_id'])\n",
    "    ).reset_index(name='target')\n",
    "\n",
    "print \"done.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing product features ...  done.\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Before splitting off the validation set, compute \"product features\".\n",
    "# These are features that depend only on product_id; their values are the\n",
    "# same for training, validation and testing.\n",
    "#\n",
    "\n",
    "print \"Computing product features ... \",\n",
    "\n",
    "#   number of users who ever had this product in their basket\n",
    "x = prior.groupby('product_id').apply(\n",
    "    lambda x: len(set(x['user_id']))).reset_index(name='nusers')\n",
    "\n",
    "# number of users that reorderd the item\n",
    "y = train.groupby('product_id').apply(\n",
    "    lambda x: x['reordered'].sum()).reset_index(name='reordered')\n",
    "\n",
    "reorder_prob = x.merge(y, on='product_id', how='left').fillna(0)\n",
    "reorder_prob['reorder_prob'] = reorder_prob['reordered'] / reorder_prob['nusers']\n",
    "del x, y, reorder_prob['reordered'], reorder_prob['nusers']\n",
    "\n",
    "#\n",
    "# FIXME: try inter-purchase time?\n",
    "#\n",
    "\n",
    "print \"done.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing user / user-product features ... \n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Generate features ...\n",
    "#\n",
    "\n",
    "print \"Computing user / user-product features ... \"\n",
    "\n",
    "prior_gb_up = prior.groupby(['user_id', 'product_id'])\n",
    "prior_gb_u = prior.groupby('user_id')\n",
    "# FIXME is there a way to reuse prior_gb_up here? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tnorders of product by user ...  done.\n"
     ]
    }
   ],
   "source": [
    "#   1: Number of times product has been ordered by user\n",
    "print \"\\tnorders of product by user ... \",\n",
    "user_prod_norders = prior_gb_up.apply(len).reset_index(name='user_prod_norders')\n",
    "print \"done.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tnorders by user ...  done.\n"
     ]
    }
   ],
   "source": [
    "#   2: Total number of orders by user\n",
    "print \"\\tnorders by user ... \",\n",
    "user_norders = prior_gb_u.apply(\n",
    "    lambda x: len(set(x['order_id']))).reset_index(name='user_norders')\n",
    "# FIXME you can also get this from orders table ... probably quicker\n",
    "print \"done.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\torder rate of product by user ...  done.\n"
     ]
    }
   ],
   "source": [
    "#   3: Fraction of user baskets containing product\n",
    "print \"\\torder rate of product by user ... \",\n",
    "user_prod_rate = user_prod_norders.merge(user_norders, on='user_id', how='left')\n",
    "user_prod_rate['user_prod_rate'] = user_prod_rate['user_prod_norders'] / 1.0 / user_prod_rate['user_norders']\n",
    "\n",
    "del user_prod_rate['user_prod_norders'], user_prod_rate['user_norders']\n",
    "# FIXME I guess you could delete the other tables instead, and this is then a bit\n",
    "# more handy to carry around, but it doesn't play nice with jupyter, where\n",
    "# I want cell execution independence ...\n",
    "\n",
    "print \"done.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tbaskets since last order of product ...  done.\n"
     ]
    }
   ],
   "source": [
    "#   4: Number of baskets since user last ordered this item\n",
    "print \"\\tbaskets since last order of product ... \",\n",
    "baskets_since = prior_gb_up.apply(\n",
    "    lambda x: max(x['order_number'])).reset_index(name='last_basket')\n",
    "\n",
    "baskets_since = baskets_since.merge(user_norders, on='user_id', how='left')\n",
    "baskets_since['baskets_since'] = baskets_since['user_norders'] - baskets_since['last_basket']\n",
    "del baskets_since['user_norders'], baskets_since['last_basket']\n",
    "print \"done.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tmean basket position ...  done.\n"
     ]
    }
   ],
   "source": [
    "#   5: Mean basket position. Lower basket position means customer likes product?\n",
    "print \"\\tmean basket position ... \",\n",
    "baskets_pos = prior_gb_up.apply(\n",
    "    lambda x: x['add_to_cart_order'].mean()).reset_index(name='basket_pos')\n",
    "print \"done.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\torder features ...  done.\n"
     ]
    }
   ],
   "source": [
    "#   6/7/8: Time of day / dow / days since prior order\n",
    "print \"\\torder features ... \",\n",
    "order_features = orders[orders['eval_set'] != 'prior'][[\n",
    "    'user_id',\n",
    "    'order_hour_of_day',\n",
    "    'order_dow',\n",
    "    'days_since_prior_order']]\n",
    "\n",
    "assert len(order_features) == len(orders['user_id'].unique())\n",
    "del prior_gb_up\n",
    "print \"done.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tuser reorder rate ...  done.\n"
     ]
    }
   ],
   "source": [
    "#    9: Does user reorder in general?\n",
    "print \"\\tuser reorder rate ... \",\n",
    "user_reorder_rate = prior_gb_u.apply(\n",
    "    lambda x: x['reordered'].sum() / 1.0 / len(set(x['order_id']))\n",
    "    ).reset_index(name='user_reorder_rate')\n",
    "print \"done.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tuser general order rate (days) ...  done.\n"
     ]
    }
   ],
   "source": [
    "#   10: User order rate\n",
    "print \"\\tuser general order rate (days) ... \",\n",
    "user_order_dt = prior_gb_u.apply(\n",
    "    lambda x: x['days_since_prior_order'].mean()\n",
    "    ).reset_index(name='user_order_dt')\n",
    "print \"done.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>user_prod_norders</th>\n",
       "      <th>user_norders</th>\n",
       "      <th>user_prod_rate</th>\n",
       "      <th>baskets_since</th>\n",
       "      <th>basket_pos</th>\n",
       "      <th>reorder_prob</th>\n",
       "      <th>order_hour_of_day</th>\n",
       "      <th>order_dow</th>\n",
       "      <th>days_since_prior_order</th>\n",
       "      <th>user_reorder_rate</th>\n",
       "      <th>user_order_dt</th>\n",
       "      <th>reordered</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>196</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.400000</td>\n",
       "      <td>0.152625</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>14.0</td>\n",
       "      <td>4.1</td>\n",
       "      <td>20.259259</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>10258</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>0.140036</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>14.0</td>\n",
       "      <td>4.1</td>\n",
       "      <td>20.259259</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>10326</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.147166</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>14.0</td>\n",
       "      <td>4.1</td>\n",
       "      <td>20.259259</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>12427</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.300000</td>\n",
       "      <td>0.095295</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>14.0</td>\n",
       "      <td>4.1</td>\n",
       "      <td>20.259259</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>13032</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "      <td>6.333333</td>\n",
       "      <td>0.090202</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>14.0</td>\n",
       "      <td>4.1</td>\n",
       "      <td>20.259259</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>13176</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.210303</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>14.0</td>\n",
       "      <td>4.1</td>\n",
       "      <td>20.259259</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>14084</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0.1</td>\n",
       "      <td>9</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.148406</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>14.0</td>\n",
       "      <td>4.1</td>\n",
       "      <td>20.259259</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>17122</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.104819</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>14.0</td>\n",
       "      <td>4.1</td>\n",
       "      <td>20.259259</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>25133</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.086335</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>14.0</td>\n",
       "      <td>4.1</td>\n",
       "      <td>20.259259</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>26088</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.2</td>\n",
       "      <td>8</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>0.066208</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>14.0</td>\n",
       "      <td>4.1</td>\n",
       "      <td>20.259259</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  product_id  user_prod_norders  user_norders  user_prod_rate  \\\n",
       "0        1         196                 10            10             1.0   \n",
       "1        1       10258                  9            10             0.9   \n",
       "2        1       10326                  1            10             0.1   \n",
       "3        1       12427                 10            10             1.0   \n",
       "4        1       13032                  3            10             0.3   \n",
       "5        1       13176                  2            10             0.2   \n",
       "6        1       14084                  1            10             0.1   \n",
       "7        1       17122                  1            10             0.1   \n",
       "8        1       25133                  8            10             0.8   \n",
       "9        1       26088                  2            10             0.2   \n",
       "\n",
       "   baskets_since  basket_pos  reorder_prob  order_hour_of_day  order_dow  \\\n",
       "0              0    1.400000      0.152625                  8          4   \n",
       "1              0    3.333333      0.140036                  8          4   \n",
       "2              5    5.000000      0.147166                  8          4   \n",
       "3              0    3.300000      0.095295                  8          4   \n",
       "4              0    6.333333      0.090202                  8          4   \n",
       "5              5    6.000000      0.210303                  8          4   \n",
       "6              9    2.000000      0.148406                  8          4   \n",
       "7              5    6.000000      0.104819                  8          4   \n",
       "8              0    4.000000      0.086335                  8          4   \n",
       "9              8    4.500000      0.066208                  8          4   \n",
       "\n",
       "   days_since_prior_order  user_reorder_rate  user_order_dt  reordered  \n",
       "0                    14.0                4.1      20.259259        1.0  \n",
       "1                    14.0                4.1      20.259259        1.0  \n",
       "2                    14.0                4.1      20.259259        0.0  \n",
       "3                    14.0                4.1      20.259259        0.0  \n",
       "4                    14.0                4.1      20.259259        1.0  \n",
       "5                    14.0                4.1      20.259259        0.0  \n",
       "6                    14.0                4.1      20.259259        0.0  \n",
       "7                    14.0                4.1      20.259259        0.0  \n",
       "8                    14.0                4.1      20.259259        1.0  \n",
       "9                    14.0                4.1      20.259259        1.0  "
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "# Assemble all features together in one table\n",
    "#\n",
    "features = user_prod_norders.merge(\n",
    "    user_norders, on='user_id', how='left'\n",
    "    ).merge(user_prod_rate, on=['user_id', 'product_id'], how='left'\n",
    "    ).merge(baskets_since, on=['user_id', 'product_id'], how='left'\n",
    "    ).merge(baskets_pos, on=['user_id', 'product_id'], how='left'            \n",
    "    ).merge(reorder_prob, on='product_id', how='left'\n",
    "    ).merge(order_features, on='user_id', how='left'\n",
    "    ).merge(user_reorder_rate, on='user_id', how='left'\n",
    "    ).merge(user_order_dt, on='user_id', how='left')\n",
    "# need to keep \"product features\" for submission stage\n",
    "\n",
    "# Add training data, i.e., whether product was reordered by user\n",
    "features = features.merge(\n",
    "    train[['user_id','product_id','reordered']],\n",
    "    on=['user_id','product_id'], how='left').fillna(0)\n",
    "\n",
    "features.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000 81209 75000 206209\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Establish separate training and validation data\n",
    "#\n",
    "\n",
    "Nval = 50000 # seems like a good number\n",
    "uids = train['user_id'].unique()\n",
    "uids_train = uids[:-Nval]\n",
    "uids_val = uids[-Nval:]\n",
    "\n",
    "feature_list = [\n",
    "    'user_prod_norders',\n",
    "    'user_norders',\n",
    "    'user_prod_rate',\n",
    "    'baskets_since',\n",
    "    'basket_pos',\n",
    "    'reorder_prob',\n",
    "    'order_dow',\n",
    "    'order_hour_of_day',\n",
    "    'days_since_prior_order',\n",
    "    'user_reorder_rate',\n",
    "    'user_order_dt']\n",
    "\n",
    "#\n",
    "# training\n",
    "#\n",
    "where = features['user_id'].isin(uids_train)\n",
    "X_train = features[where][feature_list].as_matrix()\n",
    "y_train = features[where]['reordered'].as_matrix()\n",
    "\n",
    "#\n",
    "# validation\n",
    "#\n",
    "where = features['user_id'].isin(uids_val)\n",
    "X_val = features[where][feature_list].as_matrix()\n",
    "y_val = features[where]['reordered'].as_matrix()\n",
    "\n",
    "#\n",
    "# test / submission\n",
    "#\n",
    "uids_test = orders[orders['eval_set'] == 'test']['user_id'].unique()\n",
    "where = features['user_id'].isin(uids_test)\n",
    "X_test = features[where][feature_list].as_matrix()\n",
    "\n",
    "print len(uids_val), len(uids_train), len(uids_test), len(orders['user_id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500 12 4\n",
      "[ 0.12046192  0.03096418  0.31571444  0.40639964  0.00324772  0.08775508\n",
      "  0.000771    0.0014761   0.0156764   0.00978474  0.00774877]\n",
      "500 12 6\n",
      "[ 0.14690395  0.01861904  0.1985425   0.50573722  0.00307652  0.09114301\n",
      "  0.00071677  0.00148692  0.01713427  0.01021767  0.00642212]\n",
      "500 15 4\n",
      "[ 0.14350424  0.03198534  0.27441664  0.38693112  0.00809859  0.09705579\n",
      "  0.00237265  0.00470723  0.01917868  0.01706109  0.01468862]\n",
      "500 15 6\n",
      "[ 0.14311303  0.01073528  0.19049643  0.48859906  0.00833519  0.0986176\n",
      "  0.00223062  0.00496033  0.02081556  0.01757146  0.01452546]\n",
      "500 20 4\n",
      "[ 0.1198622   0.03080946  0.25169073  0.39611477  0.01365086  0.10287036\n",
      "  0.00419992  0.00910893  0.02352386  0.02448651  0.0236824 ]\n",
      "500 20 6\n",
      "[ 0.14263695  0.0136886   0.17126197  0.46732399  0.01397023  0.10171657\n",
      "  0.00424285  0.0093701   0.02375863  0.02647399  0.02555612]\n",
      "1000 12 4\n",
      "[ 0.14110437  0.03845742  0.25119225  0.44261648  0.00336026  0.09113256\n",
      "  0.00061531  0.00122192  0.01437618  0.00923172  0.00669153]\n",
      "1000 12 6\n",
      "[ 0.14499692  0.00752965  0.19849522  0.51952478  0.00250118  0.0927718\n",
      "  0.00052284  0.00117397  0.01652687  0.01057752  0.00537924]\n",
      "1000 15 4\n",
      "[ 0.1266977   0.03305289  0.26999554  0.41554886  0.00620752  0.09941216\n",
      "  0.00150618  0.00313022  0.01791155  0.01543886  0.01109853]\n",
      "1000 15 6\n",
      "[ 0.13889658  0.00861054  0.22725566  0.47487182  0.00593246  0.09446849\n",
      "  0.00154424  0.00317618  0.01876135  0.01544752  0.01103517]\n",
      "1000 20 4\n",
      "[ 0.14711439  0.03239163  0.24713991  0.39212975  0.00881772  0.11057536\n",
      "  0.00260963  0.00527554  0.02007796  0.0183684   0.01549971]\n",
      "1000 20 6\n",
      "[ 0.15015385  0.01073801  0.17797933  0.4886245   0.00874644  0.09946527\n",
      "  0.00246119  0.0053679   0.02105595  0.01908049  0.01632706]\n",
      "1500 12 4\n",
      "[ 0.13579362  0.03306436  0.29517063  0.40395426  0.00324191  0.09664581\n",
      "  0.0005164   0.00094331  0.01486476  0.01007116  0.00573379]\n",
      "1500 12 6\n",
      "[  1.54734688e-01   9.17775063e-03   2.05928074e-01   5.02662729e-01\n",
      "   2.11290212e-03   9.33874867e-02   3.74496822e-04   9.34124674e-04\n",
      "   1.61934628e-02   9.56651653e-03   4.92776959e-03]\n",
      "1500 15 4\n",
      "[ 0.18084886  0.03689791  0.24320089  0.39458333  0.00518289  0.09799217\n",
      "  0.00118042  0.00231167  0.01648556  0.01235215  0.00896415]\n",
      "1500 15 6\n",
      "[ 0.15925806  0.00981211  0.19838064  0.49080786  0.00447044  0.09368132\n",
      "  0.00111055  0.00233503  0.01807773  0.01312677  0.00893949]\n",
      "1500 20 4\n",
      "[ 0.14168084  0.03829475  0.23077855  0.42512391  0.00690342  0.10707121\n",
      "  0.00167536  0.00344596  0.01753047  0.01555381  0.01194172]\n",
      "1500 20 6\n",
      "[ 0.1490518   0.01047143  0.17736628  0.50882435  0.00641351  0.09483582\n",
      "  0.00171721  0.00364479  0.01917422  0.01648395  0.01201663]\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Train the decision tree model(s)\n",
    "#\n",
    "\n",
    "#\n",
    "# Apparently my solution was submitted with md = 12 on accident\n",
    "#\n",
    "\n",
    "trees = []\n",
    "for mss in [500, 1000, 1500]:\n",
    "    for md in [12, 15, 20]:\n",
    "        for mf in [4, 6]:\n",
    "            print mss, md, mf\n",
    "            clf = RandomForestClassifier(\n",
    "                n_estimators=10, \n",
    "                random_state=0, \n",
    "                min_samples_split=mss,\n",
    "                max_features=mf,\n",
    "                max_depth=md,\n",
    "                n_jobs=4,\n",
    "                class_weight={0:1.0, 1:4.0},\n",
    "                verbose=0)\n",
    "            clf.fit(X_train, y_train)\n",
    "            trees.append(clf)\n",
    "            #export_graphviz(clf, out_file='tree.dot')\n",
    "            print clf.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance on training set ... \n",
      "RandomForestClassifier(bootstrap=True, class_weight={0: 1.0, 1: 4.0},\n",
      "            criterion='gini', max_depth=12, max_features=4,\n",
      "            max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "            min_samples_leaf=1, min_samples_split=500,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=4,\n",
      "            oob_score=False, random_state=0, verbose=0, warm_start=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/local/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.48 0.385586719135\n",
      "0.49 0.385678167567\n",
      "0.5 0.38565647369\n",
      "0.51 0.385031728105\n",
      "RandomForestClassifier(bootstrap=True, class_weight={0: 1.0, 1: 4.0},\n",
      "            criterion='gini', max_depth=12, max_features=6,\n",
      "            max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "            min_samples_leaf=1, min_samples_split=500,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=4,\n",
      "            oob_score=False, random_state=0, verbose=0, warm_start=False)\n",
      "0.48 0.385455232891\n",
      "0.49 0.385903780716\n",
      "0.5 0.385682917775\n",
      "0.51 0.385122380995\n",
      "RandomForestClassifier(bootstrap=True, class_weight={0: 1.0, 1: 4.0},\n",
      "            criterion='gini', max_depth=15, max_features=4,\n",
      "            max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "            min_samples_leaf=1, min_samples_split=500,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=4,\n",
      "            oob_score=False, random_state=0, verbose=0, warm_start=False)\n",
      "0.48 0.391201562597\n",
      "0.49 0.391000128794\n",
      "0.5 0.39061954762\n",
      "0.51 0.389812837375\n",
      "RandomForestClassifier(bootstrap=True, class_weight={0: 1.0, 1: 4.0},\n",
      "            criterion='gini', max_depth=15, max_features=6,\n",
      "            max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "            min_samples_leaf=1, min_samples_split=500,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=4,\n",
      "            oob_score=False, random_state=0, verbose=0, warm_start=False)\n",
      "0.48 0.392003951518\n",
      "0.49 0.39184572996\n",
      "0.5 0.391857724411\n",
      "0.51 0.391586247583\n",
      "RandomForestClassifier(bootstrap=True, class_weight={0: 1.0, 1: 4.0},\n",
      "            criterion='gini', max_depth=20, max_features=4,\n",
      "            max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "            min_samples_leaf=1, min_samples_split=500,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=4,\n",
      "            oob_score=False, random_state=0, verbose=0, warm_start=False)\n",
      "0.48 0.397584989343\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Let's see how we covered the training set\n",
    "#\n",
    "print \"Performance on training set ... \"\n",
    "this_target = target[target['user_id'].isin(uids_train)]\n",
    "this_features = features[features['user_id'].isin(uids_train)]\n",
    "for clf in trees:\n",
    "    print clf\n",
    "    pred = clf.predict_proba(X_train)[:, 1]\n",
    "    for p in [0.48, 0.49, 0.5, 0.51]: # time and time again, this value wins\n",
    "        this_features['prediction'] = pred > p\n",
    "        out = this_features.groupby('user_id').apply(\n",
    "            lambda x: set(x[x['prediction'] == True]['product_id'])\n",
    "            ).reset_index(name='prediction')\n",
    "\n",
    "        out = out.merge(this_target, on='user_id', how='left')\n",
    "        print p, f1score(out['prediction'], out['target'])\n",
    "        del this_features['prediction']\n",
    "    \n",
    "#\n",
    "# Now, how do we perform out of sample?\n",
    "#\n",
    "print \"Performance on validation set ... \"\n",
    "this_target = target[target['user_id'].isin(uids_val)]\n",
    "this_features = features[features['user_id'].isin(uids_val)]\n",
    "for clf in trees:\n",
    "    pred = clf.predict_proba(X_val)[:, 1]\n",
    "    for p in [0.48, 0.49, 0.5, 0.51]:\n",
    "        \n",
    "        this_features['prediction'] = pred > p\n",
    "        out = this_features.groupby('user_id').apply(\n",
    "            lambda x: set(x[x['prediction'] == True]['product_id'])\n",
    "            ).reset_index(name='prediction')\n",
    "\n",
    "        out = out.merge(this_target, on='user_id', how='left')\n",
    "        print p, f1score(out['prediction'], out['target'])\n",
    "        del this_features['prediction']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Optional. Retrain the model with the winning hyperparameters on the entire \n",
    "# training data set. I think this is always a good idea? Can it go wrong?\n",
    "#   (This actually went horribly wrong, giving an *in sample* F1 score of 0.1,\n",
    "#    so I'm not really sure what to make of that!)\n",
    "#\n",
    "clf = RandomForestClassifier(\n",
    "    n_estimators=100, \n",
    "    random_state=0, \n",
    "    min_samples_split=1000,\n",
    "    n_jobs=4,\n",
    "    verbose=3)\n",
    "X_all = np.vstack((X_train, X_val))\n",
    "y_all = np.concatenate((y_train, y_val))\n",
    "clf.fit(X_all, y_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the model hasn't changed too much\n",
    "\n",
    "print clf.feature_importances_ \n",
    "print trees[2].feature_importances_\n",
    "\n",
    "pred = trees[2].predict_proba(X_all)[:, 1]\n",
    "uids = np.concatenate((uids_train, uids_val))\n",
    "this_features = features[features['user_id'].isin(uids)]\n",
    "this_features['prediction'] = pred > 0.195\n",
    "this_target = target\n",
    "out = this_features.groupby('user_id').apply(\n",
    "    lambda x: set(x[x['prediction'] == True]['product_id'])\n",
    "    ).reset_index(name='prediction')\n",
    "\n",
    "out = out.merge(this_target, on='user_id', how='left')\n",
    "\n",
    "print out.head()\n",
    "print f1score(out['prediction'], out['target'])\n",
    "#del this_features['prediction']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=12, max_features=4, max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=500, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=100, n_jobs=4, oob_score=False, random_state=0,\n",
       "            verbose=5, warm_start=False)"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trees[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done   1 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=4)]: Done   2 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=4)]: Done   3 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=4)]: Done   4 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=4)]: Done   5 tasks      | elapsed:    2.3s\n",
      "[Parallel(n_jobs=4)]: Done   6 tasks      | elapsed:    2.3s\n",
      "[Parallel(n_jobs=4)]: Done   7 tasks      | elapsed:    2.4s\n",
      "[Parallel(n_jobs=4)]: Done   8 tasks      | elapsed:    2.5s\n",
      "[Parallel(n_jobs=4)]: Done   9 tasks      | elapsed:    3.6s\n",
      "[Parallel(n_jobs=4)]: Done  10 tasks      | elapsed:    3.7s\n",
      "[Parallel(n_jobs=4)]: Done  11 tasks      | elapsed:    3.7s\n",
      "[Parallel(n_jobs=4)]: Done  12 tasks      | elapsed:    3.8s\n",
      "[Parallel(n_jobs=4)]: Done  13 tasks      | elapsed:    4.8s\n",
      "[Parallel(n_jobs=4)]: Done  14 tasks      | elapsed:    4.8s\n",
      "[Parallel(n_jobs=4)]: Done  15 tasks      | elapsed:    4.8s\n",
      "[Parallel(n_jobs=4)]: Done  16 tasks      | elapsed:    5.0s\n",
      "[Parallel(n_jobs=4)]: Done  17 tasks      | elapsed:    6.0s\n",
      "[Parallel(n_jobs=4)]: Done  18 tasks      | elapsed:    6.0s\n",
      "[Parallel(n_jobs=4)]: Done  19 tasks      | elapsed:    6.0s\n",
      "[Parallel(n_jobs=4)]: Done  20 tasks      | elapsed:    6.1s\n",
      "[Parallel(n_jobs=4)]: Done  21 tasks      | elapsed:    7.1s\n",
      "[Parallel(n_jobs=4)]: Done  22 tasks      | elapsed:    7.1s\n",
      "[Parallel(n_jobs=4)]: Done  23 tasks      | elapsed:    7.2s\n",
      "[Parallel(n_jobs=4)]: Done  24 tasks      | elapsed:    7.2s\n",
      "[Parallel(n_jobs=4)]: Done  25 tasks      | elapsed:    8.3s\n",
      "[Parallel(n_jobs=4)]: Done  26 tasks      | elapsed:    8.4s\n",
      "[Parallel(n_jobs=4)]: Done  27 tasks      | elapsed:    8.6s\n",
      "[Parallel(n_jobs=4)]: Done  28 tasks      | elapsed:    8.8s\n",
      "[Parallel(n_jobs=4)]: Done  29 tasks      | elapsed:   10.0s\n",
      "[Parallel(n_jobs=4)]: Done  30 tasks      | elapsed:   11.4s\n",
      "[Parallel(n_jobs=4)]: Done  31 tasks      | elapsed:   11.5s\n",
      "[Parallel(n_jobs=4)]: Done  32 tasks      | elapsed:   11.5s\n",
      "[Parallel(n_jobs=4)]: Done  33 tasks      | elapsed:   11.8s\n",
      "[Parallel(n_jobs=4)]: Done  34 tasks      | elapsed:   13.1s\n",
      "[Parallel(n_jobs=4)]: Done  35 tasks      | elapsed:   13.1s\n",
      "[Parallel(n_jobs=4)]: Done  36 tasks      | elapsed:   13.2s\n",
      "[Parallel(n_jobs=4)]: Done  37 tasks      | elapsed:   13.2s\n",
      "[Parallel(n_jobs=4)]: Done  38 tasks      | elapsed:   14.3s\n",
      "[Parallel(n_jobs=4)]: Done  39 tasks      | elapsed:   14.4s\n",
      "[Parallel(n_jobs=4)]: Done  40 tasks      | elapsed:   14.6s\n",
      "[Parallel(n_jobs=4)]: Done  41 tasks      | elapsed:   14.6s\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:   15.7s\n",
      "[Parallel(n_jobs=4)]: Done  43 tasks      | elapsed:   15.8s\n",
      "[Parallel(n_jobs=4)]: Done  44 tasks      | elapsed:   15.8s\n",
      "[Parallel(n_jobs=4)]: Done  45 tasks      | elapsed:   15.9s\n",
      "[Parallel(n_jobs=4)]: Done  46 tasks      | elapsed:   17.2s\n",
      "[Parallel(n_jobs=4)]: Done  47 tasks      | elapsed:   17.3s\n",
      "[Parallel(n_jobs=4)]: Done  48 tasks      | elapsed:   17.4s\n",
      "[Parallel(n_jobs=4)]: Done  49 tasks      | elapsed:   17.5s\n",
      "[Parallel(n_jobs=4)]: Done  50 tasks      | elapsed:   18.7s\n",
      "[Parallel(n_jobs=4)]: Done  51 tasks      | elapsed:   18.7s\n",
      "[Parallel(n_jobs=4)]: Done  52 tasks      | elapsed:   18.8s\n",
      "[Parallel(n_jobs=4)]: Done  53 tasks      | elapsed:   18.9s\n",
      "[Parallel(n_jobs=4)]: Done  54 tasks      | elapsed:   20.3s\n",
      "[Parallel(n_jobs=4)]: Done  55 tasks      | elapsed:   20.3s\n",
      "[Parallel(n_jobs=4)]: Done  56 tasks      | elapsed:   20.4s\n",
      "[Parallel(n_jobs=4)]: Done  57 tasks      | elapsed:   20.5s\n",
      "[Parallel(n_jobs=4)]: Done  58 tasks      | elapsed:   22.1s\n",
      "[Parallel(n_jobs=4)]: Done  59 tasks      | elapsed:   22.2s\n",
      "[Parallel(n_jobs=4)]: Done  60 tasks      | elapsed:   22.2s\n",
      "[Parallel(n_jobs=4)]: Done  61 tasks      | elapsed:   22.3s\n",
      "[Parallel(n_jobs=4)]: Done  62 tasks      | elapsed:   24.1s\n",
      "[Parallel(n_jobs=4)]: Done  63 tasks      | elapsed:   24.1s\n",
      "[Parallel(n_jobs=4)]: Done  64 tasks      | elapsed:   24.4s\n",
      "[Parallel(n_jobs=4)]: Done  65 tasks      | elapsed:   24.5s\n",
      "[Parallel(n_jobs=4)]: Done  66 tasks      | elapsed:   25.7s\n",
      "[Parallel(n_jobs=4)]: Done  67 tasks      | elapsed:   25.8s\n",
      "[Parallel(n_jobs=4)]: Done  68 tasks      | elapsed:   26.0s\n",
      "[Parallel(n_jobs=4)]: Done  69 tasks      | elapsed:   26.6s\n",
      "[Parallel(n_jobs=4)]: Done  70 tasks      | elapsed:   27.3s\n",
      "[Parallel(n_jobs=4)]: Done  71 tasks      | elapsed:   27.5s\n",
      "[Parallel(n_jobs=4)]: Done  72 tasks      | elapsed:   27.5s\n",
      "[Parallel(n_jobs=4)]: Done  73 tasks      | elapsed:   28.1s\n",
      "[Parallel(n_jobs=4)]: Done  74 tasks      | elapsed:   28.7s\n",
      "[Parallel(n_jobs=4)]: Done  75 tasks      | elapsed:   29.0s\n",
      "[Parallel(n_jobs=4)]: Done  76 tasks      | elapsed:   29.0s\n",
      "[Parallel(n_jobs=4)]: Done  77 tasks      | elapsed:   29.4s\n",
      "[Parallel(n_jobs=4)]: Done  78 tasks      | elapsed:   30.0s\n",
      "[Parallel(n_jobs=4)]: Done  79 tasks      | elapsed:   30.1s\n",
      "[Parallel(n_jobs=4)]: Done  80 tasks      | elapsed:   30.4s\n",
      "[Parallel(n_jobs=4)]: Done  81 tasks      | elapsed:   31.0s\n",
      "[Parallel(n_jobs=4)]: Done  82 tasks      | elapsed:   31.8s\n",
      "[Parallel(n_jobs=4)]: Done  83 tasks      | elapsed:   32.2s\n",
      "[Parallel(n_jobs=4)]: Done  84 tasks      | elapsed:   32.4s\n",
      "[Parallel(n_jobs=4)]: Done  85 tasks      | elapsed:   32.7s\n",
      "[Parallel(n_jobs=4)]: Done  86 tasks      | elapsed:   33.4s\n",
      "[Parallel(n_jobs=4)]: Done  87 tasks      | elapsed:   33.6s\n",
      "[Parallel(n_jobs=4)]: Done  88 tasks      | elapsed:   33.7s\n",
      "[Parallel(n_jobs=4)]: Done  89 tasks      | elapsed:   34.1s\n",
      "[Parallel(n_jobs=4)]: Done  90 tasks      | elapsed:   34.7s\n",
      "[Parallel(n_jobs=4)]: Done  91 tasks      | elapsed:   35.1s\n",
      "[Parallel(n_jobs=4)]: Done  92 tasks      | elapsed:   35.1s\n",
      "[Parallel(n_jobs=4)]: Done  93 tasks      | elapsed:   35.5s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:   38.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:   38.1s finished\n",
      "/opt/local/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  del sys.path[0]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17</td>\n",
       "      <td>{13107, 21709, 47766, 21463}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34</td>\n",
       "      <td>{47792, 2596, 44632, 39180, 43504, 21137, 1608...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>137</td>\n",
       "      <td>{38689, 25890, 44422, 5134, 23794, 24852, 2326...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>182</td>\n",
       "      <td>{11520, 5479, 33000, 47209, 39275, 41149, 4767...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>257</td>\n",
       "      <td>{27104, 49235, 24838, 39475, 29837, 13870, 211...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   order_id                                         prediction\n",
       "0        17                       {13107, 21709, 47766, 21463}\n",
       "1        34  {47792, 2596, 44632, 39180, 43504, 21137, 1608...\n",
       "2       137  {38689, 25890, 44422, 5134, 23794, 24852, 2326...\n",
       "3       182  {11520, 5479, 33000, 47209, 39275, 41149, 4767...\n",
       "4       257  {27104, 49235, 24838, 39475, 29837, 13870, 211..."
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "# Let's make a submission!!\n",
    "#\n",
    "\n",
    "clf = trees[0]\n",
    "\n",
    "#\n",
    "# generate predictions for test set from model\n",
    "#\n",
    "oid_uid_test = orders[orders['eval_set'] == 'test'][['order_id', 'user_id']]\n",
    "pred = clf.predict_proba(X_test)[:, 1] > 0.41\n",
    "this_features = features[features['user_id'].isin(uids_test)]\n",
    "this_features['prediction'] = pred\n",
    "this_features = this_features.merge(oid_uid_test, on='user_id', how='left')\n",
    "out = this_features.groupby('order_id').apply(\n",
    "    lambda x: set(x[x['prediction'] == True]['product_id'])\n",
    "    ).reset_index(name='prediction')\n",
    "\n",
    "out.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Write predictions to disk for submission.\n",
    "#\n",
    "\n",
    "fd = open('submission.csv', 'w')\n",
    "fd.write('order_id,products\\n')\n",
    "\n",
    "for oid, pr in zip(out['order_id'], out['prediction']):\n",
    "    fd.write('%d,' % oid)\n",
    "\n",
    "    if pr:\n",
    "        fd.write(' '.join(map(str, pr)))\n",
    "    else:\n",
    "        fd.write('None')\n",
    "    fd.write('\\n')\n",
    "\n",
    "fd.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance on training set ... \n",
      "   user_id  product_id  user_prod_norders  user_norders  user_prod_rate  \\\n",
      "0        1         196                 10            10             1.0   \n",
      "1        1       10258                  9            10             0.9   \n",
      "2        1       10326                  1            10             0.1   \n",
      "3        1       12427                 10            10             1.0   \n",
      "4        1       13032                  3            10             0.3   \n",
      "\n",
      "   baskets_since  basket_pos  reorder_prob  order_hour_of_day  order_dow  \\\n",
      "0              0    1.400000      0.152625                  8          4   \n",
      "1              0    3.333333      0.140036                  8          4   \n",
      "2              5    5.000000      0.147166                  8          4   \n",
      "3              0    3.300000      0.095295                  8          4   \n",
      "4              0    6.333333      0.090202                  8          4   \n",
      "\n",
      "   days_since_prior_order  user_reorder_rate  user_order_dt  reordered  \n",
      "0                    14.0                4.1      20.259259        1.0  \n",
      "1                    14.0                4.1      20.259259        1.0  \n",
      "2                    14.0                4.1      20.259259        0.0  \n",
      "3                    14.0                4.1      20.259259        0.0  \n",
      "4                    14.0                4.1      20.259259        1.0  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  10 tasks      | elapsed:   11.5s\n",
      "[Parallel(n_jobs=4)]: Done  64 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:  1.8min finished\n",
      "/opt/local/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>user_prod_norders</th>\n",
       "      <th>user_norders</th>\n",
       "      <th>user_prod_rate</th>\n",
       "      <th>baskets_since</th>\n",
       "      <th>basket_pos</th>\n",
       "      <th>reorder_prob</th>\n",
       "      <th>order_hour_of_day</th>\n",
       "      <th>order_dow</th>\n",
       "      <th>days_since_prior_order</th>\n",
       "      <th>user_reorder_rate</th>\n",
       "      <th>user_order_dt</th>\n",
       "      <th>reordered</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>196</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.400000</td>\n",
       "      <td>0.152625</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>14.0</td>\n",
       "      <td>4.1</td>\n",
       "      <td>20.259259</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>10258</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>0.140036</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>14.0</td>\n",
       "      <td>4.1</td>\n",
       "      <td>20.259259</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>10326</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.147166</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>14.0</td>\n",
       "      <td>4.1</td>\n",
       "      <td>20.259259</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>12427</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.300000</td>\n",
       "      <td>0.095295</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>14.0</td>\n",
       "      <td>4.1</td>\n",
       "      <td>20.259259</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>13032</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "      <td>6.333333</td>\n",
       "      <td>0.090202</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>14.0</td>\n",
       "      <td>4.1</td>\n",
       "      <td>20.259259</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  product_id  user_prod_norders  user_norders  user_prod_rate  \\\n",
       "0        1         196                 10            10             1.0   \n",
       "1        1       10258                  9            10             0.9   \n",
       "2        1       10326                  1            10             0.1   \n",
       "3        1       12427                 10            10             1.0   \n",
       "4        1       13032                  3            10             0.3   \n",
       "\n",
       "   baskets_since  basket_pos  reorder_prob  order_hour_of_day  order_dow  \\\n",
       "0              0    1.400000      0.152625                  8          4   \n",
       "1              0    3.333333      0.140036                  8          4   \n",
       "2              5    5.000000      0.147166                  8          4   \n",
       "3              0    3.300000      0.095295                  8          4   \n",
       "4              0    6.333333      0.090202                  8          4   \n",
       "\n",
       "   days_since_prior_order  user_reorder_rate  user_order_dt  reordered  \\\n",
       "0                    14.0                4.1      20.259259        1.0   \n",
       "1                    14.0                4.1      20.259259        1.0   \n",
       "2                    14.0                4.1      20.259259        0.0   \n",
       "3                    14.0                4.1      20.259259        0.0   \n",
       "4                    14.0                4.1      20.259259        1.0   \n",
       "\n",
       "  prediction  \n",
       "0       True  \n",
       "1       True  \n",
       "2      False  \n",
       "3       True  \n",
       "4       True  "
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "#\n",
    "# POST MORTEM: WHAT WENT WRONG?\n",
    "#   what does the misclassified data look like?\n",
    "#   what features could we add to better classify them?\n",
    "#\n",
    "this_features = features[features['user_id'].isin(uids_train)]\n",
    "clf = trees[2]\n",
    "pred = clf.predict_proba(X_train)[:, 1]\n",
    "this_features['prediction'] = pred > 0.195\n",
    "this_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-190-8e7f7dbfc029>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m errors = this_features.groupby(['product_id','user_id']).apply(\n\u001b[0;32m----> 2\u001b[0;31m     lambda x: pd.Series(\n\u001b[0m\u001b[1;32m      3\u001b[0m         {'false_pos':sum((x['prediction'] == 1) & (x['reordered'] == 0)),\n\u001b[1;32m      4\u001b[0m          \u001b[0;34m'false_neg'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'prediction'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'reordered'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m          \u001b[0;34m'true_pos'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'prediction'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'reordered'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/local/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/pandas/core/groupby.pyc\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    692\u001b[0m         \u001b[0;31m# ignore SettingWithCopy here in case the user mutates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    693\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0moption_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mode.chained_assignment'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 694\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_python_apply_general\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    695\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    696\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_python_apply_general\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/local/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/pandas/core/groupby.pyc\u001b[0m in \u001b[0;36m_python_apply_general\u001b[0;34m(self, f)\u001b[0m\n\u001b[1;32m    696\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_python_apply_general\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    697\u001b[0m         keys, values, mutated = self.grouper.apply(f, self._selected_obj,\n\u001b[0;32m--> 698\u001b[0;31m                                                    self.axis)\n\u001b[0m\u001b[1;32m    699\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m         return self._wrap_applied_output(\n",
      "\u001b[0;32m/opt/local/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/pandas/core/groupby.pyc\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, f, data, axis)\u001b[0m\n\u001b[1;32m   1593\u001b[0m                 hasattr(splitter, 'fast_apply') and axis == 0):\n\u001b[1;32m   1594\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1595\u001b[0;31m                 \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmutated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplitter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfast_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1596\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mgroup_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmutated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1597\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidApply\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/local/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/pandas/core/groupby.pyc\u001b[0m in \u001b[0;36mfast_apply\u001b[0;34m(self, f, names)\u001b[0m\n\u001b[1;32m   4061\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4062\u001b[0m         \u001b[0msdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_sorted_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4063\u001b[0;31m         \u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmutated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_frame_axis0\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstarts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mends\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4064\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4065\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmutated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/src/reduce.pyx\u001b[0m in \u001b[0;36mpandas.lib.apply_frame_axis0 (pandas/lib.c:41747)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-190-8e7f7dbfc029>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      3\u001b[0m         {'false_pos':sum((x['prediction'] == 1) & (x['reordered'] == 0)),\n\u001b[1;32m      4\u001b[0m          \u001b[0;34m'false_neg'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'prediction'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'reordered'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m          \u001b[0;34m'true_pos'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'prediction'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'reordered'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m          'true_neg':sum((x['prediction'] == 0) & (x['reordered'] == 0))})\n\u001b[1;32m      7\u001b[0m ).reset_index().merge(pd.read_csv('products.csv'), on='product_id')\n",
      "\u001b[0;32m/opt/local/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/pandas/core/ops.pyc\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    917\u001b[0m                       else fill_bool)\n\u001b[1;32m    918\u001b[0m             return filler(self._constructor(na_op(self.values, other.values),\n\u001b[0;32m--> 919\u001b[0;31m                                             index=self.index, name=name))\n\u001b[0m\u001b[1;32m    920\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    921\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/local/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/pandas/core/ops.pyc\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    905\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    906\u001b[0m         \u001b[0mfill_int\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 907\u001b[0;31m         \u001b[0mfill_bool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    908\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    909\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_align_method_SERIES\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malign_asobject\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/local/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/pandas/core/series.pyc\u001b[0m in \u001b[0;36mfillna\u001b[0;34m(self, value, method, axis, inplace, limit, downcast, **kwargs)\u001b[0m\n\u001b[1;32m   2368\u001b[0m                                           \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2369\u001b[0m                                           \u001b[0mlimit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdowncast\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdowncast\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2370\u001b[0;31m                                           **kwargs)\n\u001b[0m\u001b[1;32m   2371\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2372\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mAppender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgeneric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shared_docs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'shift'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0m_shared_doc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/local/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/pandas/core/generic.pyc\u001b[0m in \u001b[0;36mfillna\u001b[0;34m(self, value, method, axis, inplace, limit, downcast)\u001b[0m\n\u001b[1;32m   3211\u001b[0m             \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3212\u001b[0m         \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis_number\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3213\u001b[0;31m         \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmissing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclean_fill_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3215\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/local/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/pandas/core/missing.pyc\u001b[0m in \u001b[0;36mclean_fill_method\u001b[0;34m(method, allow_nearest)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mclean_fill_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_nearest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;31m# asfreq is compat for resampling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'asfreq'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "errors = this_features.groupby(['product_id','user_id']).apply(\n",
    "    lambda x: pd.Series(\n",
    "        {'false_pos':sum((x['prediction'] == 1) & (x['reordered'] == 0)),\n",
    "         'false_neg':sum((x['prediction'] == 0) & (x['reordered'] == 1)),\n",
    "         'true_pos':sum((x['prediction'] == 1) & (x['reordered'] == 1)),\n",
    "         'true_neg':sum((x['prediction'] == 0) & (x['reordered'] == 0))})\n",
    ").reset_index().merge(pd.read_csv('products.csv'), on='product_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "errors.sort_values('false_neg', ascending=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.07906365,  0.03530213,  0.23368996,  0.1513633 ,  0.06063451,\n",
       "        0.14184713,  0.02117745,  0.04417509,  0.05227964,  0.08449257,\n",
       "        0.09597457])"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_list = [\n",
    "    'user_prod_norders',\n",
    "    'user_norders',\n",
    "    'user_prod_rate',\n",
    "    'baskets_since',\n",
    "    'basket_pos',\n",
    "    'reorder_prob',\n",
    "    'order_dow',\n",
    "    'order_hour_of_day',\n",
    "    'days_since_prior_order',\n",
    "    'user_reorder_rate',\n",
    "    'user_order_dt']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
