{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from collections import Counter\n",
    "from evaluate import f1score\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pylab\n",
    "pylab.rcParams['figure.figsize'] = (10, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Reading and merging orders tables ...  done.\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Read in training (and validation) data\n",
    "# \n",
    "\n",
    "print \"Reading and merging orders tables ... \",\n",
    "\n",
    "train = pd.read_csv('order_products__train.csv')\n",
    "prior = pd.read_csv('order_products__prior.csv')\n",
    "orders = pd.read_csv('orders.csv')\n",
    "products = pd.read_csv('products.csv')\n",
    "\n",
    "train = train.merge(\n",
    "    orders, on='order_id', how='left').merge(\n",
    "    products, on='product_id', how='left')\n",
    "prior = prior.merge(\n",
    "    orders, on='order_id', how='left').merge(\n",
    "    products, on='product_id', how='left')\n",
    "\n",
    "# compute training target\n",
    "target = train.groupby('user_id'\n",
    "    ).apply(lambda x: set(x[x['reordered'] == True]['product_id'])\n",
    "    ).reset_index(name='target')\n",
    "\n",
    "print \"done.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   product_id\n",
       "0           1\n",
       "1           2\n",
       "2           3\n",
       "3           4\n",
       "4           5"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "# Before splitting off the validation set, compute \"product features\".\n",
    "# These are features that depend only on product_id; their values are the\n",
    "# same for training, validation and testing.\n",
    "#\n",
    "nprods = len(products['product_id'].unique())\n",
    "prod_features = pd.DataFrame(\n",
    "    index=range(nprods),\n",
    "    columns=['product_id'])\n",
    "prod_features['product_id'] = products['product_id'].unique()\n",
    "prod_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>dept_reorder_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.574180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.346721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.653460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.541885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.346721</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   product_id  dept_reorder_prob\n",
       "0           1           0.574180\n",
       "1           2           0.346721\n",
       "2           3           0.653460\n",
       "3           4           0.541885\n",
       "4           5           0.346721"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "#   2: Department reorder probability\n",
    "#\n",
    "x = prior.groupby('department_id').apply(\n",
    "    lambda x: sum(x['reordered']) / 1.0 / len(x) ).reset_index(name='dept_reorder_prob')\n",
    "x = x.merge(products, on='department_id', how='left')\n",
    "\n",
    "prod_features = prod_features.merge(\n",
    "    x[['product_id', 'dept_reorder_prob']], on='product_id', how='left')\n",
    "\n",
    "prod_features.head()\n",
    "#\n",
    "# CHECKME: Why do these numbers seem so different from (1)??\n",
    "#\n",
    "\n",
    "#\n",
    "# ANSWER: Because you are computing slightly different things. The\n",
    "# query below gives an number more similar to the category reorder\n",
    "# rate. See also below where I now compute prod prob differently.\n",
    "#\n",
    "\n",
    "#   number of users who ever had this product in their basket\n",
    "# x = prior.groupby('product_id').apply(\n",
    "#    lambda x: sum(x['reordered']) / 1.0 / len(x)).reset_index(name='reorder_prob2')\n",
    "\n",
    "# prod_features = prod_features.merge(\n",
    "#    x[['product_id', 'reorder_prob2']], on='product_id', how='left')\n",
    "# prod_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>dept_reorder_prob</th>\n",
       "      <th>department_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.574180</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.346721</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.653460</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.541885</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.346721</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   product_id  dept_reorder_prob  department_id\n",
       "0           1           0.574180              0\n",
       "1           2           0.346721              0\n",
       "2           3           0.653460              0\n",
       "3           4           0.541885              0\n",
       "4           5           0.346721              0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "#   3: Department ID heuristic split\n",
    "#\n",
    "prod_features = prod_features.merge(\n",
    "    products[['product_id', 'department_id']], on='product_id', how='left')\n",
    "prod_features['department_id'] = prod_features.apply(\n",
    "    lambda x: 1 if x['department_id'] in [4, 16] else 0, axis=1)\n",
    "prod_features.head()\n",
    "\n",
    "# sanity check\n",
    "# prod_features[prod_features['department_id'] == 1].merge(\n",
    "#    products, on='product_id', how='left')['department_id_y'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>dept_reorder_prob</th>\n",
       "      <th>department_id</th>\n",
       "      <th>is_organic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.574180</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.346721</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.653460</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.541885</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.346721</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   product_id  dept_reorder_prob  department_id  is_organic\n",
       "0           1           0.574180              0           0\n",
       "1           2           0.346721              0           0\n",
       "2           3           0.653460              0           0\n",
       "3           4           0.541885              0           0\n",
       "4           5           0.346721              0           0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "#   4: People love to reorder organic \n",
    "#\n",
    "prod_features = prod_features.merge(\n",
    "    products[['product_id', 'product_name']], on='product_id', how='left')\n",
    "prod_features['is_organic'] = prod_features.apply(\n",
    "    lambda x: 1 if 'organic' in x['product_name'].lower() else 0, axis=1)\n",
    "del prod_features['product_name']\n",
    "prod_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>dept_reorder_prob</th>\n",
       "      <th>department_id</th>\n",
       "      <th>is_organic</th>\n",
       "      <th>reorder_prob</th>\n",
       "      <th>mean_hod</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.574180</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.185367</td>\n",
       "      <td>13.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.346721</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.086042</td>\n",
       "      <td>11.916667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.653460</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.167777</td>\n",
       "      <td>11.773399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.541885</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.195368</td>\n",
       "      <td>13.952381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.346721</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.220588</td>\n",
       "      <td>9.222222</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   product_id  dept_reorder_prob  department_id  is_organic  reorder_prob  \\\n",
       "0           1           0.574180              0           0      0.185367   \n",
       "1           2           0.346721              0           0      0.086042   \n",
       "2           3           0.653460              0           0      0.167777   \n",
       "3           4           0.541885              0           0      0.195368   \n",
       "4           5           0.346721              0           0      0.220588   \n",
       "\n",
       "    mean_hod  \n",
       "0  13.250000  \n",
       "1  11.916667  \n",
       "2  11.773399  \n",
       "3  13.952381  \n",
       "4   9.222222  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "#   5: Some items are ordered at certain times? \n",
    "#\n",
    "prod_features = prod_features.merge(\n",
    "    prior.groupby('product_id').apply(\n",
    "        lambda x: x[x['reordered']==1]['order_hour_of_day'].mean()\n",
    "        ).reset_index(name='mean_hod'),\n",
    "    on='product_id', how='left')\n",
    "prod_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>dept_reorder_prob</th>\n",
       "      <th>department_id</th>\n",
       "      <th>is_organic</th>\n",
       "      <th>reorder_prob</th>\n",
       "      <th>mean_hod</th>\n",
       "      <th>mean_dow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.574180</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.185367</td>\n",
       "      <td>13.250000</td>\n",
       "      <td>2.720070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.346721</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.086042</td>\n",
       "      <td>11.916667</td>\n",
       "      <td>2.916667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.653460</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.167777</td>\n",
       "      <td>11.773399</td>\n",
       "      <td>2.753695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.541885</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.195368</td>\n",
       "      <td>13.952381</td>\n",
       "      <td>2.605442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.346721</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.220588</td>\n",
       "      <td>9.222222</td>\n",
       "      <td>3.111111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   product_id  dept_reorder_prob  department_id  is_organic  reorder_prob  \\\n",
       "0           1           0.574180              0           0      0.185367   \n",
       "1           2           0.346721              0           0      0.086042   \n",
       "2           3           0.653460              0           0      0.167777   \n",
       "3           4           0.541885              0           0      0.195368   \n",
       "4           5           0.346721              0           0      0.220588   \n",
       "\n",
       "    mean_hod  mean_dow  \n",
       "0  13.250000  2.720070  \n",
       "1  11.916667  2.916667  \n",
       "2  11.773399  2.753695  \n",
       "3  13.952381  2.605442  \n",
       "4   9.222222  3.111111  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "#   5: Some items are ordered at certain times? \n",
    "#\n",
    "prod_features = prod_features.merge(\n",
    "    prior.groupby('product_id').apply(\n",
    "        lambda x: x[x['reordered']==1]['order_dow'].mean()\n",
    "        ).reset_index(name='mean_dow'),\n",
    "    on='product_id', how='left')\n",
    "prod_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>dept_reorder_prob</th>\n",
       "      <th>department_id</th>\n",
       "      <th>is_organic</th>\n",
       "      <th>reorder_prob</th>\n",
       "      <th>mean_hod</th>\n",
       "      <th>mean_dow</th>\n",
       "      <th>aisle_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.574180</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.185367</td>\n",
       "      <td>13.250000</td>\n",
       "      <td>2.720070</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.346721</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.086042</td>\n",
       "      <td>11.916667</td>\n",
       "      <td>2.916667</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.653460</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.167777</td>\n",
       "      <td>11.773399</td>\n",
       "      <td>2.753695</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.541885</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.195368</td>\n",
       "      <td>13.952381</td>\n",
       "      <td>2.605442</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.346721</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.220588</td>\n",
       "      <td>9.222222</td>\n",
       "      <td>3.111111</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   product_id  dept_reorder_prob  department_id  is_organic  reorder_prob  \\\n",
       "0           1           0.574180              0           0      0.185367   \n",
       "1           2           0.346721              0           0      0.086042   \n",
       "2           3           0.653460              0           0      0.167777   \n",
       "3           4           0.541885              0           0      0.195368   \n",
       "4           5           0.346721              0           0      0.220588   \n",
       "\n",
       "    mean_hod  mean_dow  aisle_id  \n",
       "0  13.250000  2.720070        61  \n",
       "1  11.916667  2.916667       104  \n",
       "2  11.773399  2.753695        94  \n",
       "3  13.952381  2.605442        38  \n",
       "4   9.222222  3.111111         5  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "#   6: Aisles --> product category? Can the DT handle a \"category\" feature? \n",
    "#\n",
    "prod_features = prod_features.merge(\n",
    "    products[['product_id','aisle_id']],\n",
    "    on='product_id', how='left')\n",
    "prod_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Computing user / user-product features ... \n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Generate user features ... \n",
    "# FIXME make pretty and organized like prod_features\n",
    "#\n",
    "\n",
    "print \"Computing user / user-product features ... \"\n",
    "\n",
    "prior_gb_up = prior.groupby(['user_id', 'product_id'])\n",
    "prior_gb_u = prior.groupby('user_id')\n",
    "# FIXME is there a way to reuse prior_gb_up here? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tnorders of product by user ...  done.\n"
     ]
    }
   ],
   "source": [
    "#   1: Number of times product has been ordered by user\n",
    "print \"\\tnorders of product by user ... \",\n",
    "user_prod_norders = prior_gb_up.apply(len).reset_index(name='user_prod_norders')\n",
    "print \"done.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tnorders by user ...  done.\n"
     ]
    }
   ],
   "source": [
    "#   2: Total number of orders by user\n",
    "print \"\\tnorders by user ... \",\n",
    "user_norders = prior_gb_u.apply(\n",
    "    lambda x: len(set(x['order_id']))).reset_index(name='user_norders')\n",
    "# FIXME you can also get this from orders table ... probably quicker\n",
    "print \"done.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\torder rate of product by user ...  done.\n"
     ]
    }
   ],
   "source": [
    "#   3: Fraction of user baskets containing product\n",
    "print \"\\torder rate of product by user ... \",\n",
    "user_prod_rate = user_prod_norders.merge(user_norders, on='user_id', how='left')\n",
    "user_prod_rate['user_prod_rate'] = user_prod_rate['user_prod_norders'] / 1.0 / user_prod_rate['user_norders']\n",
    "\n",
    "del user_prod_rate['user_prod_norders'], user_prod_rate['user_norders']\n",
    "# FIXME I guess you could delete the other tables instead, and this is then a bit\n",
    "# more handy to carry around, but it doesn't play nice with jupyter, where\n",
    "# I want cell execution independence ...\n",
    "\n",
    "print \"done.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tbaskets since last order of product ...  done.\n"
     ]
    }
   ],
   "source": [
    "#   4: Number of baskets since user last ordered this item\n",
    "# FIXME why is this so slow?!\n",
    "print \"\\tbaskets since last order of product ... \",\n",
    "baskets_since = prior_gb_up.apply(\n",
    "    lambda x: max(x['order_number'])).reset_index(name='last_basket')\n",
    "\n",
    "baskets_since = baskets_since.merge(user_norders, on='user_id', how='left')\n",
    "baskets_since['baskets_since'] = baskets_since['user_norders'] - baskets_since['last_basket']\n",
    "del baskets_since['user_norders'], baskets_since['last_basket']\n",
    "print \"done.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tbaskets since first order of product ...  done.\n"
     ]
    }
   ],
   "source": [
    "#   5: Number of baskets since user first ordered this item\n",
    "# FIXME why is this so slow?!\n",
    "print \"\\tbaskets since first order of product ... \",\n",
    "baskets_since_1st = prior_gb_up.apply(\n",
    "    lambda x: min(x['order_number'])).reset_index(name='last_basket')\n",
    "\n",
    "baskets_since_1st = baskets_since_1st.merge(user_norders, on='user_id', how='left')\n",
    "baskets_since_1st['baskets_since_1st'] = baskets_since_1st['user_norders'] - baskets_since_1st['last_basket']\n",
    "del baskets_since_1st['user_norders'], baskets_since_1st['last_basket']\n",
    "print \"done.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#   1: Product reorder probability\n",
    "#\n",
    "\n",
    "# The way I was originally computing this may have been biased.\n",
    "# Below is an unbiased (i.e. without peeking at the training\n",
    "# set) way to estimate the probability a product is ordered in\n",
    "# a basket given that it ever appeared in a basket.\n",
    "\n",
    "x = user_prod_norders.merge(\n",
    "    baskets_since_1st, on=['user_id','product_id'], how='left'\n",
    "    ).groupby('product_id').apply(\n",
    "    lambda x: sum( x['user_prod_norders'] ) / 1.0 / (1 + sum( x['baskets_since_1st'] ))\n",
    "    ).reset_index(name='reorder_prob')\n",
    "\n",
    "prod_features = prod_features.merge(\n",
    "    x[['product_id', 'reorder_prob']], on='product_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tmean basket position ...  done.\n"
     ]
    }
   ],
   "source": [
    "#   6: Mean basket position. Lower basket position means customer likes product?\n",
    "print \"\\tmean basket position ... \",\n",
    "baskets_pos = prior_gb_up.apply(\n",
    "    lambda x: x['add_to_cart_order'].mean()).reset_index(name='basket_pos')\n",
    "print \"done.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\torder features ...  done.\n"
     ]
    }
   ],
   "source": [
    "#   7/8/9: Time of day / dow / days since prior order\n",
    "print \"\\torder features ... \",\n",
    "order_features = orders[orders['eval_set'] != 'prior'][[\n",
    "    'user_id',\n",
    "    'order_hour_of_day',\n",
    "    'order_dow',\n",
    "    'days_since_prior_order']]\n",
    "\n",
    "assert len(order_features) == len(orders['user_id'].unique())\n",
    "print \"done.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tuser reorder rate ...  done.\n"
     ]
    }
   ],
   "source": [
    "#    10: Does user reorder in general?\n",
    "print \"\\tuser reorder rate ... \",\n",
    "user_reorder_rate = prior_gb_u.apply(\n",
    "    lambda x: x['reordered'].sum() / 1.0 / len(x)\n",
    "    ).reset_index(name='user_reorder_rate')\n",
    "print \"done.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tuser general order rate (days) ...  done.\n"
     ]
    }
   ],
   "source": [
    "#   11: User order rate\n",
    "print \"\\tuser general order rate (days) ... \",\n",
    "user_order_dt = prior_gb_u.apply(\n",
    "    lambda x: x['days_since_prior_order'].mean()\n",
    "    ).reset_index(name='user_order_dt')\n",
    "print \"done.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tuser product order rate (days) ... "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-624021728807>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'order_number'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mmn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'days_since_prior_order'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m1.0\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmx\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mmn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m user_prod_order_dt = prior_gb_up.apply(up_order_rate\n\u001b[0m\u001b[1;32m     13\u001b[0m     ).reset_index(name='user_prod_order_dt')\n\u001b[1;32m     14\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0;34m\"done.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/local/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/pandas/core/groupby.pyc\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    692\u001b[0m         \u001b[0;31m# ignore SettingWithCopy here in case the user mutates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    693\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0moption_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mode.chained_assignment'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 694\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_python_apply_general\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    695\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    696\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_python_apply_general\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/local/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/pandas/core/groupby.pyc\u001b[0m in \u001b[0;36m_python_apply_general\u001b[0;34m(self, f)\u001b[0m\n\u001b[1;32m    696\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_python_apply_general\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    697\u001b[0m         keys, values, mutated = self.grouper.apply(f, self._selected_obj,\n\u001b[0;32m--> 698\u001b[0;31m                                                    self.axis)\n\u001b[0m\u001b[1;32m    699\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m         return self._wrap_applied_output(\n",
      "\u001b[0;32m/opt/local/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/pandas/core/groupby.pyc\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, f, data, axis)\u001b[0m\n\u001b[1;32m   1593\u001b[0m                 hasattr(splitter, 'fast_apply') and axis == 0):\n\u001b[1;32m   1594\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1595\u001b[0;31m                 \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmutated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplitter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfast_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1596\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mgroup_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmutated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1597\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidApply\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/local/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/pandas/core/groupby.pyc\u001b[0m in \u001b[0;36mfast_apply\u001b[0;34m(self, f, names)\u001b[0m\n\u001b[1;32m   4061\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4062\u001b[0m         \u001b[0msdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_sorted_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4063\u001b[0;31m         \u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmutated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_frame_axis0\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstarts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mends\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4064\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4065\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmutated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/src/reduce.pyx\u001b[0m in \u001b[0;36mpandas.lib.apply_frame_axis0 (pandas/lib.c:41747)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-55-624021728807>\u001b[0m in \u001b[0;36mup_order_rate\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'order_number'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mmn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'days_since_prior_order'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m1.0\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmx\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mmn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m user_prod_order_dt = prior_gb_up.apply(up_order_rate\n",
      "\u001b[0;32m/opt/local/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2051\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2052\u001b[0m             \u001b[0;31m# either boolean or fancy integer index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2053\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2054\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2055\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/local/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m_getitem_array\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2093\u001b[0m             \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_bool_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2094\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2095\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2096\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2097\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_to_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/local/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/pandas/core/generic.pyc\u001b[0m in \u001b[0;36mtake\u001b[0;34m(self, indices, axis, convert, is_copy, **kwargs)\u001b[0m\n\u001b[1;32m   1667\u001b[0m         new_data = self._data.take(indices,\n\u001b[1;32m   1668\u001b[0m                                    \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_block_manager_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1669\u001b[0;31m                                    convert=True, verify=True)\n\u001b[0m\u001b[1;32m   1670\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1671\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/local/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/pandas/core/internals.pyc\u001b[0m in \u001b[0;36mtake\u001b[0;34m(self, indexer, axis, verify, convert)\u001b[0m\n\u001b[1;32m   3960\u001b[0m                                 'the axis length')\n\u001b[1;32m   3961\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3962\u001b[0;31m         \u001b[0mnew_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3963\u001b[0m         return self.reindex_indexer(new_axis=new_labels, indexer=indexer,\n\u001b[1;32m   3964\u001b[0m                                     axis=axis, allow_dups=True)\n",
      "\u001b[0;32m/opt/local/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/pandas/indexes/base.pyc\u001b[0m in \u001b[0;36mtake\u001b[0;34m(self, indices, axis, allow_fill, fill_value, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Unable to fill values because {0} cannot contain NA'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0mtaken\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shallow_copy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtaken\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#   12: User product order rate.\n",
    "print \"\\tuser product order rate (days) ... \",\n",
    "def up_order_rate(x):\n",
    "    mn = min(x['order_number'])\n",
    "    mx = max(x['order_number']) # we actually want max over all products\n",
    "                                # this will have to do for now\n",
    "    if mn == mx:\n",
    "        return 0\n",
    "    else:\n",
    "        return sum(x[x['order_number'] >= mn]['days_since_prior_order']) / 1.0 / (mx - mn)\n",
    "\n",
    "user_prod_order_dt = prior_gb_up.apply(up_order_rate\n",
    "    ).reset_index(name='user_prod_order_dt')\n",
    "print \"done.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>user_prod_norders</th>\n",
       "      <th>user_norders</th>\n",
       "      <th>user_prod_rate</th>\n",
       "      <th>baskets_since</th>\n",
       "      <th>baskets_since_1st</th>\n",
       "      <th>basket_pos</th>\n",
       "      <th>dept_reorder_prob</th>\n",
       "      <th>department_id</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_hod</th>\n",
       "      <th>mean_dow</th>\n",
       "      <th>aisle_id</th>\n",
       "      <th>order_hour_of_day</th>\n",
       "      <th>order_dow</th>\n",
       "      <th>days_since_prior_order</th>\n",
       "      <th>user_reorder_rate</th>\n",
       "      <th>user_order_dt</th>\n",
       "      <th>order_streak</th>\n",
       "      <th>reordered</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>196</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>1.400000</td>\n",
       "      <td>0.653460</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>12.409989</td>\n",
       "      <td>2.868555</td>\n",
       "      <td>77</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.694915</td>\n",
       "      <td>20.259259</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>10258</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>0.574180</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>12.027358</td>\n",
       "      <td>2.715623</td>\n",
       "      <td>117</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.694915</td>\n",
       "      <td>20.259259</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>10326</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.649913</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>12.829031</td>\n",
       "      <td>2.729115</td>\n",
       "      <td>24</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.694915</td>\n",
       "      <td>20.259259</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>12427</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>3.300000</td>\n",
       "      <td>0.574180</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>12.098812</td>\n",
       "      <td>2.643319</td>\n",
       "      <td>23</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.694915</td>\n",
       "      <td>20.259259</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>13032</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>6.333333</td>\n",
       "      <td>0.560922</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>12.451521</td>\n",
       "      <td>2.754564</td>\n",
       "      <td>121</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.694915</td>\n",
       "      <td>20.259259</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>13176</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.649913</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>13.342547</td>\n",
       "      <td>2.699180</td>\n",
       "      <td>24</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.694915</td>\n",
       "      <td>20.259259</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>14084</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0.1</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.669969</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>13.372127</td>\n",
       "      <td>2.695272</td>\n",
       "      <td>91</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.694915</td>\n",
       "      <td>20.259259</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>17122</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.649913</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>12.629092</td>\n",
       "      <td>2.622800</td>\n",
       "      <td>24</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.694915</td>\n",
       "      <td>20.259259</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>25133</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.669969</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>12.871130</td>\n",
       "      <td>2.648495</td>\n",
       "      <td>21</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.694915</td>\n",
       "      <td>20.259259</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>26088</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.2</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>0.574180</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>13.042647</td>\n",
       "      <td>2.918382</td>\n",
       "      <td>23</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.694915</td>\n",
       "      <td>20.259259</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows  22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  product_id  user_prod_norders  user_norders  user_prod_rate  \\\n",
       "0        1         196                 10            10             1.0   \n",
       "1        1       10258                  9            10             0.9   \n",
       "2        1       10326                  1            10             0.1   \n",
       "3        1       12427                 10            10             1.0   \n",
       "4        1       13032                  3            10             0.3   \n",
       "5        1       13176                  2            10             0.2   \n",
       "6        1       14084                  1            10             0.1   \n",
       "7        1       17122                  1            10             0.1   \n",
       "8        1       25133                  8            10             0.8   \n",
       "9        1       26088                  2            10             0.2   \n",
       "\n",
       "   baskets_since  baskets_since_1st  basket_pos  dept_reorder_prob  \\\n",
       "0              0                  9    1.400000           0.653460   \n",
       "1              0                  8    3.333333           0.574180   \n",
       "2              5                  5    5.000000           0.649913   \n",
       "3              0                  9    3.300000           0.574180   \n",
       "4              0                  8    6.333333           0.560922   \n",
       "5              5                  8    6.000000           0.649913   \n",
       "6              9                  9    2.000000           0.669969   \n",
       "7              5                  5    6.000000           0.649913   \n",
       "8              0                  7    4.000000           0.669969   \n",
       "9              8                  9    4.500000           0.574180   \n",
       "\n",
       "   department_id    ...       mean_hod  mean_dow  aisle_id  order_hour_of_day  \\\n",
       "0              0    ...      12.409989  2.868555        77                  8   \n",
       "1              0    ...      12.027358  2.715623       117                  8   \n",
       "2              1    ...      12.829031  2.729115        24                  8   \n",
       "3              0    ...      12.098812  2.643319        23                  8   \n",
       "4              0    ...      12.451521  2.754564       121                  8   \n",
       "5              1    ...      13.342547  2.699180        24                  8   \n",
       "6              1    ...      13.372127  2.695272        91                  8   \n",
       "7              1    ...      12.629092  2.622800        24                  8   \n",
       "8              1    ...      12.871130  2.648495        21                  8   \n",
       "9              0    ...      13.042647  2.918382        23                  8   \n",
       "\n",
       "   order_dow  days_since_prior_order  user_reorder_rate  user_order_dt  \\\n",
       "0          4                    14.0           0.694915      20.259259   \n",
       "1          4                    14.0           0.694915      20.259259   \n",
       "2          4                    14.0           0.694915      20.259259   \n",
       "3          4                    14.0           0.694915      20.259259   \n",
       "4          4                    14.0           0.694915      20.259259   \n",
       "5          4                    14.0           0.694915      20.259259   \n",
       "6          4                    14.0           0.694915      20.259259   \n",
       "7          4                    14.0           0.694915      20.259259   \n",
       "8          4                    14.0           0.694915      20.259259   \n",
       "9          4                    14.0           0.694915      20.259259   \n",
       "\n",
       "   order_streak  reordered  \n",
       "0           5.0        1.0  \n",
       "1           5.0        1.0  \n",
       "2           0.0        0.0  \n",
       "3           5.0        0.0  \n",
       "4           1.0        1.0  \n",
       "5           0.0        0.0  \n",
       "6           0.0        0.0  \n",
       "7           0.0        0.0  \n",
       "8           5.0        1.0  \n",
       "9           0.0        1.0  \n",
       "\n",
       "[10 rows x 22 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "# Assemble all features together in one table\n",
    "#\n",
    "features = user_prod_norders.merge(\n",
    "    user_norders, on='user_id', how='left'\n",
    "    ).merge(user_prod_rate, on=['user_id', 'product_id'], how='left'\n",
    "    ).merge(baskets_since, on=['user_id', 'product_id'], how='left'\n",
    "    ).merge(baskets_since_1st, on=['user_id', 'product_id'], how='left'\n",
    "    ).merge(baskets_pos, on=['user_id', 'product_id'], how='left'            \n",
    "    ).merge(prod_features, on='product_id', how='left'\n",
    "    ).merge(order_features, on='user_id', how='left'\n",
    "    ).merge(user_reorder_rate, on='user_id', how='left'\n",
    "    ).merge(user_order_dt, on='user_id', how='left'\n",
    "    #).merge(user_prod_order_dt, on='user_id', how='left'\n",
    "    ).merge(pd.read_csv('order_streaks.csv'), on=['user_id','product_id'], how='left')\n",
    "# need to keep \"product features\" for submission stage\n",
    "\n",
    "# Add training data, i.e., whether product was reordered by user\n",
    "features = features.merge(\n",
    "    train[['user_id','product_id','reordered']],\n",
    "    on=['user_id','product_id'], how='left').fillna(0)\n",
    "\n",
    "features.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000 81209 75000 206209\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Establish separate training and validation data\n",
    "#\n",
    "\n",
    "Nval = 50000 # seems like a good number\n",
    "uids = train['user_id'].unique()\n",
    "uids_train = uids[:-Nval]\n",
    "uids_val = uids[-Nval:]\n",
    "\n",
    "feature_list = [\n",
    "    'reorder_prob', # product features\n",
    "    'dept_reorder_prob',\n",
    "    'department_id',\n",
    "    'is_organic',\n",
    "    'aisle_id',\n",
    "    'mean_hod',\n",
    "    'mean_dow',\n",
    "    'user_prod_norders', # user-product features\n",
    "    'user_prod_rate',\n",
    "    'baskets_since',\n",
    "    'baskets_since_1st',\n",
    "    'basket_pos',\n",
    "    'order_dow', # order features\n",
    "    'order_hour_of_day',\n",
    "    'days_since_prior_order',\n",
    "    'user_norders', # user features\n",
    "    'user_reorder_rate',\n",
    "    'user_order_dt',\n",
    "    #'user_prod_order_dt',\n",
    "    'order_streak']\n",
    "\n",
    "#\n",
    "# training\n",
    "#\n",
    "where = features['user_id'].isin(uids_train)\n",
    "X_train = features[where][feature_list].as_matrix()\n",
    "y_train = features[where]['reordered'].as_matrix()\n",
    "\n",
    "#\n",
    "# validation\n",
    "#\n",
    "where = features['user_id'].isin(uids_val)\n",
    "X_val = features[where][feature_list].as_matrix()\n",
    "y_val = features[where]['reordered'].as_matrix()\n",
    "\n",
    "#\n",
    "# test / submission\n",
    "#\n",
    "uids_test = orders[orders['eval_set'] == 'test']['user_id'].unique()\n",
    "where = features['user_id'].isin(uids_test)\n",
    "X_test = features[where][feature_list].as_matrix()\n",
    "\n",
    "print len(uids_val), len(uids_train), len(uids_test), len(orders['user_id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Compute training target(s)\n",
    "#\n",
    "target = train.groupby('user_id'\n",
    "    ).apply(lambda x: set(x[x['reordered'] == True]['product_id'])\n",
    "    ).reset_index(name='target')\n",
    "train_target = target[target['user_id'].isin(uids_train)]\n",
    "train_features = features[features['user_id'].isin(uids_train)]\n",
    "val_target = target[target['user_id'].isin(uids_val)]\n",
    "val_features = features[features['user_id'].isin(uids_val)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.5915           24.67m\n",
      "         2           0.5321           25.03m\n",
      "         3           0.5147           25.42m\n",
      "         4           0.5090           25.03m\n",
      "         5           0.5070           24.47m\n",
      "         6           0.5057           23.72m\n",
      "         7           0.5046           23.51m\n",
      "         8           0.5030           23.21m\n",
      "         9           0.5009           22.87m\n",
      "        10           0.5002           22.35m\n",
      "        11           0.4996           22.14m\n",
      "        12           0.4990           21.96m\n",
      "        13           0.4984           21.66m\n",
      "        14           0.4981           21.29m\n",
      "        15           0.4975           21.04m\n",
      "        16           0.4969           20.80m\n",
      "        17           0.4967           20.57m\n",
      "        18           0.4961           20.32m\n",
      "        19           0.4960           20.11m\n",
      "        20           0.4957           19.82m\n",
      "        21           0.4954           19.53m\n",
      "        22           0.4953           19.21m\n",
      "        23           0.4951           19.02m\n",
      "        24           0.4949           18.79m\n",
      "        25           0.4947           18.57m\n",
      "        26           0.4945           18.32m\n",
      "        27           0.4943           17.98m\n",
      "        28           0.4942           17.74m\n",
      "        29           0.4941           17.44m\n",
      "        30           0.4940           17.17m\n",
      "        31           0.4939           16.94m\n",
      "        32           0.4937           16.69m\n",
      "        33           0.4936           16.41m\n",
      "        34           0.4935           16.14m\n",
      "        35           0.4933           15.91m\n",
      "        36           0.4932           15.62m\n",
      "        37           0.4930           15.39m\n",
      "        38           0.4930           15.15m\n",
      "        39           0.4929           14.91m\n",
      "        40           0.4928           14.65m\n",
      "        41           0.4928           14.41m\n",
      "        42           0.4926           14.17m\n",
      "        43           0.4925           13.93m\n",
      "        44           0.4924           13.70m\n",
      "        45           0.4922           13.49m\n",
      "        46           0.4922           13.21m\n",
      "        47           0.4921           12.97m\n",
      "        48           0.4920           12.74m\n",
      "        49           0.4920           12.48m\n",
      "        50           0.4919           12.23m\n",
      "        51           0.4918           11.99m\n",
      "        52           0.4917           11.77m\n",
      "        53           0.4916           11.49m\n",
      "        54           0.4915           11.25m\n",
      "        55           0.4915           11.00m\n",
      "        56           0.4914           10.77m\n",
      "        57           0.4913           10.53m\n",
      "        58           0.4913           10.29m\n",
      "        59           0.4912           10.05m\n",
      "        60           0.4912            9.79m\n",
      "        61           0.4912            9.53m\n",
      "        62           0.4911            9.29m\n",
      "        63           0.4911            9.03m\n",
      "        64           0.4909            8.80m\n",
      "        65           0.4908            8.56m\n",
      "        66           0.4908            8.31m\n",
      "        67           0.4907            8.07m\n",
      "        68           0.4906            7.83m\n",
      "        69           0.4905            7.58m\n",
      "        70           0.4905            7.33m\n",
      "        71           0.4904            7.08m\n",
      "        72           0.4903            6.84m\n",
      "        73           0.4903            6.60m\n",
      "        74           0.4902            6.36m\n",
      "        75           0.4902            6.12m\n",
      "        76           0.4901            5.88m\n",
      "        77           0.4901            5.63m\n",
      "        78           0.4901            5.38m\n",
      "        79           0.4900            5.13m\n",
      "        80           0.4900            4.88m\n",
      "        81           0.4899            4.64m\n",
      "        82           0.4899            4.40m\n",
      "        83           0.4899            4.15m\n",
      "        84           0.4899            3.90m\n",
      "        85           0.4899            3.64m\n",
      "        86           0.4898            3.40m\n",
      "        87           0.4898            3.15m\n",
      "        88           0.4898            2.91m\n",
      "        89           0.4897            2.67m\n",
      "        90           0.4897            2.43m\n",
      "        91           0.4897            2.18m\n",
      "        92           0.4896            1.94m\n",
      "        93           0.4896            1.70m\n",
      "        94           0.4895            1.45m\n",
      "        95           0.4895            1.21m\n",
      "        96           0.4895           58.08s\n",
      "        97           0.4895           43.56s\n",
      "        98           0.4894           29.09s\n",
      "        99           0.4894           14.53s\n",
      "       100           0.4893            0.00s\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# All the cool kids are using gradient boosting ...\n",
    "#\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "clf = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0,\n",
    "     max_depth=3, min_samples_split=500, random_state=0, verbose=5).fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print \"Performance on training set ... \"\n",
    "pred = clf.predict_proba(X_train)[:, 1]\n",
    "for p in [0.195, 0.2]: # time and time again, this value wins\n",
    "    train_features['prediction'] = pred > p\n",
    "    out = train_features.groupby('user_id').apply(\n",
    "        lambda x: set(x[x['prediction'] == True]['product_id'])\n",
    "        ).reset_index(name='prediction')\n",
    "    out = out.merge(train_target, on='user_id', how='left')\n",
    "    f1 = f1score(out['prediction'], out['target'])\n",
    "    print p, f1\n",
    "\n",
    "# 0.195 0.376389954484\n",
    "# 0.2 0.376154126071    \n",
    "\n",
    "pred = clf.predict_proba(X_val)[:, 1]\n",
    "for p in [0.195, 0.2]: # time and time again, this value wins\n",
    "    val_features['prediction'] = pred > p\n",
    "    out = val_features.groupby('user_id').apply(\n",
    "        lambda x: set(x[x['prediction'] == True]['product_id'])\n",
    "        ).reset_index(name='prediction')\n",
    "    out = out.merge(val_target, on='user_id', how='left')\n",
    "    f1 = f1score(out['prediction'], out['target'])\n",
    "    print p, f1    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# try a bunch of hyperparameters\n",
    "#\n",
    "trees = []\n",
    "import itertools\n",
    "for mss, md, mf in itertools.product(\n",
    "    [1000, 1500], \n",
    "    [10, 15, 18], \n",
    "    [4, 6]):\n",
    "\n",
    "    clf = RandomForestClassifier(\n",
    "        criterion='gini',\n",
    "        n_estimators=15, \n",
    "        random_state=0, \n",
    "        min_samples_split=mss,\n",
    "        max_features=mf,\n",
    "        max_depth=md,\n",
    "        n_jobs=4,\n",
    "        verbose=0)\n",
    "    print clf\n",
    "    clf.fit(X_train, y_train)\n",
    "    trees.append(clf)\n",
    "    #export_graphviz(clf, out_file='tree.dot')\n",
    "    print clf.feature_importances_\n",
    "               \n",
    "    print \"Performance on training set ... \"\n",
    "    pred = clf.predict_proba(X_train)[:, 1]\n",
    "    for p in [0.195, 0.2, 0.21]: # time and time again, this value wins\n",
    "        train_features['prediction'] = pred > p\n",
    "        out = train_features.groupby('user_id').apply(\n",
    "            lambda x: set(x[x['prediction'] == True]['product_id'])\n",
    "            ).reset_index(name='prediction')\n",
    "        out = out.merge(train_target, on='user_id', how='left')\n",
    "        f1 = f1score(out['prediction'], out['target'])\n",
    "        print p, f1\n",
    "    \n",
    "    if f1 < 0.38: continue\n",
    "    print \"Performance on validation set ... \"\n",
    "    pred = clf.predict_proba(X_val)[:, 1]\n",
    "    for p in [0.195, 0.2, 0.21]:\n",
    "        \n",
    "        val_features['prediction'] = pred > p\n",
    "        out = val_features.groupby('user_id').apply(\n",
    "            lambda x: set(x[x['prediction'] == True]['product_id'])\n",
    "            ).reset_index(name='prediction')\n",
    "        out = out.merge(val_target, on='user_id', how='left')\n",
    "        print p, f1score(out['prediction'], out['target'])\n",
    "        del val_features['prediction']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Optional. Retrain the model with the winning hyperparameters on the entire \n",
    "# training data set. I think this is always a good idea? Can it go wrong?\n",
    "\n",
    "#\n",
    "# This model was somewhat over-fitted on the training data.\n",
    "# But it had a decent validation score. let's give it more data \n",
    "# and hope for the best :/. Nothing else is working ...\n",
    "#\n",
    "clf = RandomForestClassifier(\n",
    "                n_estimators=50, \n",
    "                random_state=0, \n",
    "                min_samples_split=500,\n",
    "                max_features=6,\n",
    "                max_depth=15,\n",
    "                n_jobs=4,\n",
    "                verbose=15)\n",
    "X_all = np.vstack((X_train, X_val))\n",
    "y_all = np.concatenate((y_train, y_val))\n",
    "clf.fit(X_all, y_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the model hasn't changed too much\n",
    "\n",
    "print clf.feature_importances_ \n",
    "#print trees[2].feature_importances_\n",
    "\n",
    "uids = np.concatenate((uids_train, uids_val))\n",
    "\n",
    "where = features['user_id'].isin(uids)\n",
    "X_all = features[where][feature_list].as_matrix()\n",
    "pred = clf.predict_proba(X_all)[:, 1]\n",
    "\n",
    "this_features = features[where]\n",
    "this_features['prediction'] = pred > 0.195\n",
    "\n",
    "out = this_features.groupby('user_id').apply(\n",
    "    lambda x: set(x[x['prediction'] == True]['product_id'])\n",
    "    ).reset_index(name='prediction')\n",
    "out = out.merge(target, on='user_id', how='left')\n",
    "\n",
    "print f1score(out['target'], out['prediction'])\n",
    "#del this_features['prediction']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trees[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Let's make a submission!!\n",
    "#\n",
    "print clf\n",
    "#clf = trees[4]\n",
    "\n",
    "#\n",
    "# generate predictions for test set from model\n",
    "#\n",
    "oid_uid_test = orders[orders['eval_set'] == 'test'][['order_id', 'user_id']]\n",
    "where = features['user_id'].isin(uids_test)\n",
    "test_features = features[where]\n",
    "\n",
    "X_test = test_features[feature_list].as_matrix()\n",
    "pred = clf.predict_proba(X_test)[:, 1] > 0.195\n",
    "\n",
    "test_features.loc[:, 'prediction'] = pred\n",
    "test_features = test_features.merge(oid_uid_test, on='user_id', how='left')\n",
    "out = this_features.groupby('order_id').apply(\n",
    "    lambda x: set(x[x['prediction'] == True]['product_id'])\n",
    "    ).reset_index(name='prediction')\n",
    "\n",
    "out.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Write predictions to disk for submission.\n",
    "#\n",
    "\n",
    "fd = open('submission.csv', 'w')\n",
    "fd.write('order_id,products\\n')\n",
    "\n",
    "for oid, pr in zip(out['order_id'], out['prediction']):\n",
    "    fd.write('%d,' % oid)\n",
    "\n",
    "    if pr:\n",
    "        fd.write(' '.join(map(str, pr)))\n",
    "    else:\n",
    "        fd.write('None')\n",
    "    fd.write('\\n')\n",
    "\n",
    "fd.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#\n",
    "# POST MORTEM: WHAT WENT WRONG?\n",
    "#   what does the misclassified data look like?\n",
    "#   what features could we add to better classify them?\n",
    "#\n",
    "\n",
    "#pred = clf.predict_proba(X_train)[:, 1]\n",
    "#train_features['prediction'] = pred > 0.195\n",
    "#train_features[train_features['prediction'] != train_features['reordered']].head(25)\n",
    "def pd_f1score(x):\n",
    "    # an F1 score routine working with dataframes\n",
    "    pr = set(x[x['prediction'] == True]['product_id'])\n",
    "    ob = set(x[x['reordered'] == 1]['product_id'])\n",
    "    if not pr:\n",
    "        pr = set([None])\n",
    "\n",
    "    if not ob:\n",
    "        ob = set([None])\n",
    "        \n",
    "    precision = len(pr & ob) / float(len(pr))\n",
    "    recall = len(pr & ob) / float(len(ob))\n",
    "\n",
    "    if precision == recall == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return 2 * precision * recall / (precision + recall)\n",
    "    \n",
    "f1scores = train_features.groupby('user_id').apply(pd_f1score).reset_index(name='f1score')\n",
    "f1scores.sort_values('f1score').head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#print prior.groupby('user_id').apply(lambda x: len(set(x['orderf1scores['f1score'].mean()\n",
    "#tmp = train_features[train_features['user_id'] == 30542].head(25)\n",
    "tmp = user_reorder_rate.merge(f1scores, on='user_id')\n",
    "pylab.scatter(tmp['user_reorder_rate'], tmp['f1score'], s=5)\n",
    "pylab.show()\n",
    "#tmp[tmp['prediction'] != tmp['reordered']].head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = train_features.groupby('product_id').apply(\n",
    "    lambda x: pd.Series(\n",
    "        {'false_pos':sum((x['prediction'] == 1) & (x['reordered'] == 0)),\n",
    "         'false_neg':sum((x['prediction'] == 0) & (x['reordered'] == 1)),\n",
    "         'true_pos':sum((x['prediction'] == 1) & (x['reordered'] == 1)),\n",
    "         'true_neg':sum((x['prediction'] == 0) & (x['reordered'] == 0))})\n",
    ").reset_index().merge(pd.read_csv('products.csv'), on='product_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors['recall'] = errors['true_pos'] / 1.0 / (errors['false_neg'] + errors['true_pos'])\n",
    "errors['precision'] = errors['true_pos'] / 1.0 / (errors['false_pos'] + errors['true_pos'])\n",
    "errors['f1score'] = 2 * errors['precision'] * errors['recall'] / (errors['precision'] + errors['recall'])\n",
    "\n",
    "errors[errors['false_pos'] + errors['true_pos'] > 50].sort_values('f1score')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = prior.groupby('product_id').apply(len).reset_index(name='norders')\n",
    "tmp = tmp.merge(errors, on='product_id', how='inner')\n",
    "tmp.sort_values('norders', ascending=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#t = prior.groupby('product_id').apply(len)\n",
    "pylab.hist(t, bins=np.linspace(1, 100, 100))\n",
    "pylab.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the product f1 score is not quite the same as the user f1score\n",
    "print errors['f1score'].mean()\n",
    "\n",
    "# I don't know if one tracks the other ... hopefully\n",
    "\n",
    "# Let's retrain part of the classifier on products we performed poorly\n",
    "# on. Kind of like making a hyper-tree where this is the first split\n",
    "bad_products = errors[errors['f1score'] < 0.4]['product_id']\n",
    "print len(bad_products)\n",
    "\n",
    "# Are there a lot of these? Enough to think it will matter?\n",
    "print len( features[features['product_id'].isin(bad_products)] )\n",
    "print len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Although these are only 1/10th of the product selection, they amount to\n",
    "# almsot 1/3rd of the orders ...\n",
    "retrain_features = train_features[train_features['product_id'].isin(bad_products)]\n",
    "X_retrain = retrain_features[feature_list].as_matrix()\n",
    "y_retrain = retrain_features['reordered'].as_matrix()\n",
    "old_clf = clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrees = []\n",
    "for mss in [500, 1000, 1500]:\n",
    "    for md in [6, 10, 15]:\n",
    "        for mf in [4, 6]:\n",
    "            print mss, md, mf\n",
    "            reclf = RandomForestClassifier(\n",
    "                n_estimators=15, \n",
    "                random_state=0, \n",
    "                min_samples_split=mss,\n",
    "                max_features=mf,\n",
    "                max_depth=md,\n",
    "                n_jobs=4,\n",
    "                verbose=0)\n",
    "            reclf.fit(X_retrain, y_retrain)\n",
    "            retrees.append(reclf)\n",
    "            #export_graphviz(clf, out_file='tree.dot')\n",
    "            print reclf.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute training target(s)\n",
    "\n",
    "# first, deep tree\n",
    "pred = clf.predict_proba(X_train)[:, 1]\n",
    "train_features['prediction'] = pred > 0.195\n",
    "\n",
    "# first, deep tree\n",
    "pred = clf.predict_proba(X_val)[:, 1]\n",
    "val_features['prediction'] = pred > 0.195"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "where_t = train_features['product_id'].isin(bad_products)\n",
    "X_retrain = train_features[where_t][feature_list].as_matrix()\n",
    "where_v = val_features['product_id'].isin(bad_products)\n",
    "X_reval = val_features[where_v][feature_list].as_matrix()\n",
    "\n",
    "print \"Original model:\",\n",
    "f1scores = train_features.groupby('user_id').apply(\n",
    "    pd_f1score).reset_index(name='f1score')\n",
    "print f1scores['f1score'].mean(), \"(training)\"\n",
    "f1scores = val_features.groupby('user_id').apply(\n",
    "    pd_f1score).reset_index(name='f1score')\n",
    "print f1scores['f1score'].mean(), \"(validation)\"\n",
    "print\n",
    "\n",
    "print \"Boosted model:\"\n",
    "\n",
    "for _clf in retrees:\n",
    "    print _clf\n",
    "\n",
    "    _pred = _clf.predict_proba(X_retrain)[:, 1]\n",
    "    for p in [0.195]: # time and time again, this value wins\n",
    "        \n",
    "        train_features.loc[where_t, 'prediction'] = _pred > p\n",
    "        f1scores = train_features.groupby('user_id').apply(\n",
    "            pd_f1score).reset_index(name='f1score')\n",
    "        print f1scores['f1score'].mean(), \"(training)\", \"(training)\"        \n",
    "        \n",
    "        #f1scores = train_features.groupby('user_id').apply(\n",
    "        #    pd_f1score).reset_index(name='f1score')\n",
    "        #print p, f1scores['f1score'].mean()\n",
    "    \n",
    "    print \"Performance on validation set ... \"\n",
    "    _pred = _clf.predict_proba(X_reval)[:, 1]\n",
    "    for p in [0.195]:\n",
    "        \n",
    "        val_features.loc[where_v, 'prediction'] = _pred > p\n",
    "        f1scores = val_features.groupby('user_id').apply(\n",
    "            pd_f1score).reset_index(name='f1score')\n",
    "        print p, f1scores['f1score'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Let's make a submission!!\n",
    "#\n",
    "print clf\n",
    "_clf = trees[1]\n",
    "print _clf\n",
    "\n",
    "#\n",
    "# generate predictions for test set from model\n",
    "#\n",
    "oid_uid_test = orders[orders['eval_set'] == 'test'][['order_id', 'user_id']]\n",
    "where = features['user_id'].isin(uids_test)\n",
    "test_features = features[where]\n",
    "where_p = test_features['product_id'].isin(bad_products)\n",
    "\n",
    "X_test = test_features[feature_list].as_matrix()\n",
    "pred = clf.predict_proba(X_test)[:, 1] > 0.195\n",
    "\n",
    "test_features.loc[:, 'prediction'] = pred\n",
    "\n",
    "X_retest = test_features[where_p][feature_list].as_matrix()\n",
    "_pred = _clf.predict_proba(X_retest)[:, 1] > 0.195\n",
    "test_features.loc[where_p, 'prediction'] = _pred\n",
    "\n",
    "test_features = test_features.merge(oid_uid_test, on='user_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = test_features.groupby('order_id').apply(\n",
    "    lambda x: set(x[x['prediction'] == True]['product_id'])\n",
    "    ).reset_index(name='prediction')\n",
    "\n",
    "out.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Write predictions to disk for submission.\n",
    "#\n",
    "\n",
    "fd = open('submission.csv', 'w')\n",
    "fd.write('order_id,products\\n')\n",
    "\n",
    "for oid, pr in zip(out['order_id'], out['prediction']):\n",
    "    fd.write('%d,' % oid)\n",
    "\n",
    "    if pr:\n",
    "        fd.write(' '.join(map(str, pr)))\n",
    "    else:\n",
    "        fd.write('None')\n",
    "    fd.write('\\n')\n",
    "\n",
    "fd.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
