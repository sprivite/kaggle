{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from collections import Counter\n",
    "from evaluate import f1score\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pylab\n",
    "pylab.rcParams['figure.figsize'] = (10, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Reading and merging orders tables ...  done.\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Read in training (and validation) data\n",
    "# \n",
    "\n",
    "print \"Reading and merging orders tables ... \",\n",
    "\n",
    "train = pd.read_csv('order_products__train.csv')\n",
    "prior = pd.read_csv('order_products__prior.csv')\n",
    "orders = pd.read_csv('orders.csv')\n",
    "products = pd.read_csv('products.csv')\n",
    "\n",
    "train = train.merge(\n",
    "    orders, on='order_id', how='left').merge(\n",
    "    products, on='product_id', how='left')\n",
    "prior = prior.merge(\n",
    "    orders, on='order_id', how='left').merge(\n",
    "    products, on='product_id', how='left')\n",
    "\n",
    "# compute training target\n",
    "target = train.groupby('user_id'\n",
    "    ).apply(lambda x: set(x[x['reordered'] == True]['product_id'])\n",
    "    ).reset_index(name='target')\n",
    "\n",
    "print \"done.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   product_id\n",
       "0           1\n",
       "1           2\n",
       "2           3\n",
       "3           4\n",
       "4           5"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "# Before splitting off the validation set, compute \"product features\".\n",
    "# These are features that depend only on product_id; their values are the\n",
    "# same for training, validation and testing.\n",
    "#\n",
    "nprods = len(products['product_id'].unique())\n",
    "prod_features = pd.DataFrame(\n",
    "    index=range(nprods),\n",
    "    columns=['product_id'])\n",
    "prod_features['product_id'] = products['product_id'].unique()\n",
    "prod_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>dept_reorder_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.574180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.346721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.653460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.541885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.346721</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   product_id  dept_reorder_prob\n",
       "0           1           0.574180\n",
       "1           2           0.346721\n",
       "2           3           0.653460\n",
       "3           4           0.541885\n",
       "4           5           0.346721"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "#   2: Department reorder probability\n",
    "#\n",
    "x = prior.groupby('department_id').apply(\n",
    "    lambda x: sum(x['reordered']) / 1.0 / len(x) ).reset_index(name='dept_reorder_prob')\n",
    "x = x.merge(products, on='department_id', how='left')\n",
    "\n",
    "prod_features = prod_features.merge(\n",
    "    x[['product_id', 'dept_reorder_prob']], on='product_id', how='left')\n",
    "\n",
    "prod_features.head()\n",
    "#\n",
    "# CHECKME: Why do these numbers seem so different from (1)??\n",
    "#\n",
    "\n",
    "#\n",
    "# ANSWER: Because you are computing slightly different things. The\n",
    "# query below gives an number more similar to the category reorder\n",
    "# rate. See also below where I now compute prod prob differently.\n",
    "#\n",
    "\n",
    "#   number of users who ever had this product in their basket\n",
    "# x = prior.groupby('product_id').apply(\n",
    "#    lambda x: sum(x['reordered']) / 1.0 / len(x)).reset_index(name='reorder_prob2')\n",
    "\n",
    "# prod_features = prod_features.merge(\n",
    "#    x[['product_id', 'reorder_prob2']], on='product_id', how='left')\n",
    "# prod_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>dept_reorder_prob</th>\n",
       "      <th>department_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.574180</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.346721</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.653460</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.541885</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.346721</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   product_id  dept_reorder_prob  department_id\n",
       "0           1           0.574180              0\n",
       "1           2           0.346721              0\n",
       "2           3           0.653460              0\n",
       "3           4           0.541885              0\n",
       "4           5           0.346721              0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "#   3: Department ID heuristic split\n",
    "#\n",
    "prod_features = prod_features.merge(\n",
    "    products[['product_id', 'department_id']], on='product_id', how='left')\n",
    "prod_features['department_id'] = prod_features.apply(\n",
    "    lambda x: 1 if x['department_id'] in [4, 16] else 0, axis=1)\n",
    "prod_features.head()\n",
    "\n",
    "# sanity check\n",
    "# prod_features[prod_features['department_id'] == 1].merge(\n",
    "#    products, on='product_id', how='left')['department_id_y'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>dept_reorder_prob</th>\n",
       "      <th>department_id</th>\n",
       "      <th>is_organic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.574180</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.346721</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.653460</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.541885</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.346721</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   product_id  dept_reorder_prob  department_id  is_organic\n",
       "0           1           0.574180              0           0\n",
       "1           2           0.346721              0           0\n",
       "2           3           0.653460              0           0\n",
       "3           4           0.541885              0           0\n",
       "4           5           0.346721              0           0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "#   4: People love to reorder organic \n",
    "#\n",
    "prod_features = prod_features.merge(\n",
    "    products[['product_id', 'product_name']], on='product_id', how='left')\n",
    "prod_features['is_organic'] = prod_features.apply(\n",
    "    lambda x: 1 if 'organic' in x['product_name'].lower() else 0, axis=1)\n",
    "del prod_features['product_name']\n",
    "prod_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Computing user / user-product features ... \n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Generate user features ... \n",
    "# FIXME make pretty and organized like prod_features\n",
    "#\n",
    "\n",
    "print \"Computing user / user-product features ... \"\n",
    "\n",
    "prior_gb_up = prior.groupby(['user_id', 'product_id'])\n",
    "prior_gb_u = prior.groupby('user_id')\n",
    "# FIXME is there a way to reuse prior_gb_up here? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tnorders of product by user ...  done.\n"
     ]
    }
   ],
   "source": [
    "#   1: Number of times product has been ordered by user\n",
    "print \"\\tnorders of product by user ... \",\n",
    "user_prod_norders = prior_gb_up.apply(len).reset_index(name='user_prod_norders')\n",
    "print \"done.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tnorders by user ...  done.\n"
     ]
    }
   ],
   "source": [
    "#   2: Total number of orders by user\n",
    "print \"\\tnorders by user ... \",\n",
    "user_norders = prior_gb_u.apply(\n",
    "    lambda x: len(set(x['order_id']))).reset_index(name='user_norders')\n",
    "# FIXME you can also get this from orders table ... probably quicker\n",
    "print \"done.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\torder rate of product by user ...  done.\n"
     ]
    }
   ],
   "source": [
    "#   3: Fraction of user baskets containing product\n",
    "print \"\\torder rate of product by user ... \",\n",
    "user_prod_rate = user_prod_norders.merge(user_norders, on='user_id', how='left')\n",
    "user_prod_rate['user_prod_rate'] = user_prod_rate['user_prod_norders'] / 1.0 / user_prod_rate['user_norders']\n",
    "\n",
    "del user_prod_rate['user_prod_norders'], user_prod_rate['user_norders']\n",
    "# FIXME I guess you could delete the other tables instead, and this is then a bit\n",
    "# more handy to carry around, but it doesn't play nice with jupyter, where\n",
    "# I want cell execution independence ...\n",
    "\n",
    "print \"done.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tbaskets since last order of product ...  done.\n"
     ]
    }
   ],
   "source": [
    "#   4: Number of baskets since user last ordered this item\n",
    "# FIXME why is this so slow?!\n",
    "print \"\\tbaskets since last order of product ... \",\n",
    "baskets_since = prior_gb_up.apply(\n",
    "    lambda x: max(x['order_number'])).reset_index(name='last_basket')\n",
    "\n",
    "baskets_since = baskets_since.merge(user_norders, on='user_id', how='left')\n",
    "baskets_since['baskets_since'] = baskets_since['user_norders'] - baskets_since['last_basket']\n",
    "del baskets_since['user_norders'], baskets_since['last_basket']\n",
    "print \"done.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tbaskets since first order of product ...  done.\n"
     ]
    }
   ],
   "source": [
    "#   5: Number of baskets since user first ordered this item\n",
    "# FIXME why is this so slow?!\n",
    "print \"\\tbaskets since first order of product ... \",\n",
    "baskets_since_1st = prior_gb_up.apply(\n",
    "    lambda x: min(x['order_number'])).reset_index(name='last_basket')\n",
    "\n",
    "baskets_since_1st = baskets_since_1st.merge(user_norders, on='user_id', how='left')\n",
    "baskets_since_1st['baskets_since_1st'] = baskets_since_1st['user_norders'] - baskets_since_1st['last_basket']\n",
    "del baskets_since_1st['user_norders'], baskets_since_1st['last_basket']\n",
    "print \"done.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#   1: Product reorder probability\n",
    "#\n",
    "\n",
    "# The way I was originally computing this may have been biased.\n",
    "# Below is an unbiased (i.e. without peeking at the training\n",
    "# set) way to estimate the probability a product is ordered in\n",
    "# a basket given that it ever appeared in a basket.\n",
    "\n",
    "x = user_prod_norders.merge(\n",
    "    baskets_since_1st, on=['user_id','product_id'], how='left'\n",
    "    ).groupby('product_id').apply(\n",
    "    lambda x: sum( x['user_prod_norders'] ) / 1.0 / (1 + sum( x['baskets_since_1st'] ))\n",
    "    ).reset_index(name='reorder_prob')\n",
    "\n",
    "prod_features = prod_features.merge(\n",
    "    x[['product_id', 'reorder_prob']], on='product_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tmean basket position ...  done.\n"
     ]
    }
   ],
   "source": [
    "#   6: Mean basket position. Lower basket position means customer likes product?\n",
    "print \"\\tmean basket position ... \",\n",
    "baskets_pos = prior_gb_up.apply(\n",
    "    lambda x: x['add_to_cart_order'].mean()).reset_index(name='basket_pos')\n",
    "print \"done.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\torder features ...  done.\n"
     ]
    }
   ],
   "source": [
    "#   7/8/9: Time of day / dow / days since prior order\n",
    "print \"\\torder features ... \",\n",
    "order_features = orders[orders['eval_set'] != 'prior'][[\n",
    "    'user_id',\n",
    "    'order_hour_of_day',\n",
    "    'order_dow',\n",
    "    'days_since_prior_order']]\n",
    "\n",
    "assert len(order_features) == len(orders['user_id'].unique())\n",
    "print \"done.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tuser reorder rate ...  done.\n"
     ]
    }
   ],
   "source": [
    "#    10: Does user reorder in general?\n",
    "print \"\\tuser reorder rate ... \",\n",
    "user_reorder_rate = prior_gb_u.apply(\n",
    "    lambda x: x['reordered'].sum() / 1.0 / len(x)\n",
    "    ).reset_index(name='user_reorder_rate')\n",
    "print \"done.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tuser general order rate (days) ...  done.\n"
     ]
    }
   ],
   "source": [
    "#   11: User order rate\n",
    "print \"\\tuser general order rate (days) ... \",\n",
    "user_order_dt = prior_gb_u.apply(\n",
    "    lambda x: x['days_since_prior_order'].mean()\n",
    "    ).reset_index(name='user_order_dt')\n",
    "print \"done.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tuser product order rate (days) ... "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-624021728807>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'order_number'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mmn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'days_since_prior_order'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m1.0\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmx\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mmn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m user_prod_order_dt = prior_gb_up.apply(up_order_rate\n\u001b[0m\u001b[1;32m     13\u001b[0m     ).reset_index(name='user_prod_order_dt')\n\u001b[1;32m     14\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0;34m\"done.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/local/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/pandas/core/groupby.pyc\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    692\u001b[0m         \u001b[0;31m# ignore SettingWithCopy here in case the user mutates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    693\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0moption_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mode.chained_assignment'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 694\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_python_apply_general\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    695\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    696\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_python_apply_general\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/local/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/pandas/core/groupby.pyc\u001b[0m in \u001b[0;36m_python_apply_general\u001b[0;34m(self, f)\u001b[0m\n\u001b[1;32m    696\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_python_apply_general\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    697\u001b[0m         keys, values, mutated = self.grouper.apply(f, self._selected_obj,\n\u001b[0;32m--> 698\u001b[0;31m                                                    self.axis)\n\u001b[0m\u001b[1;32m    699\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m         return self._wrap_applied_output(\n",
      "\u001b[0;32m/opt/local/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/pandas/core/groupby.pyc\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, f, data, axis)\u001b[0m\n\u001b[1;32m   1593\u001b[0m                 hasattr(splitter, 'fast_apply') and axis == 0):\n\u001b[1;32m   1594\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1595\u001b[0;31m                 \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmutated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplitter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfast_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1596\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mgroup_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmutated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1597\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidApply\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/local/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/pandas/core/groupby.pyc\u001b[0m in \u001b[0;36mfast_apply\u001b[0;34m(self, f, names)\u001b[0m\n\u001b[1;32m   4061\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4062\u001b[0m         \u001b[0msdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_sorted_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4063\u001b[0;31m         \u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmutated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_frame_axis0\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstarts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mends\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4064\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4065\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmutated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/src/reduce.pyx\u001b[0m in \u001b[0;36mpandas.lib.apply_frame_axis0 (pandas/lib.c:41747)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-39-624021728807>\u001b[0m in \u001b[0;36mup_order_rate\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'order_number'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mmn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'days_since_prior_order'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m1.0\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmx\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mmn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m user_prod_order_dt = prior_gb_up.apply(up_order_rate\n",
      "\u001b[0;32m/opt/local/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/pandas/core/ops.pyc\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, other, axis)\u001b[0m\n\u001b[1;32m    852\u001b[0m                 \u001b[0mother\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 854\u001b[0;31m             \u001b[0;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ignore'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    855\u001b[0m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mna_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    856\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misscalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/local/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/numpy/core/numeric.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m   3083\u001b[0m     \u001b[0;31m# without a from __future__ import with_statement\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3084\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3085\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3086\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'call'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Unspecified\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3087\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#   12: User product order rate.\n",
    "print \"\\tuser product order rate (days) ... \",\n",
    "def up_order_rate(x):\n",
    "    mn = min(x['order_number'])\n",
    "    mx = max(x['order_number']) # we actually want max over all products\n",
    "                                # this will have to do for now\n",
    "    if mn == mx:\n",
    "        return 0\n",
    "    else:\n",
    "        return sum(x[x['order_number'] >= mn]['days_since_prior_order']) / 1.0 / (mx - mn)\n",
    "\n",
    "user_prod_order_dt = prior_gb_up.apply(up_order_rate\n",
    "    ).reset_index(name='user_prod_order_dt')\n",
    "print \"done.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>user_prod_norders</th>\n",
       "      <th>user_norders</th>\n",
       "      <th>user_prod_rate</th>\n",
       "      <th>baskets_since</th>\n",
       "      <th>baskets_since_1st</th>\n",
       "      <th>basket_pos</th>\n",
       "      <th>dept_reorder_prob</th>\n",
       "      <th>department_id</th>\n",
       "      <th>is_organic</th>\n",
       "      <th>reorder_prob</th>\n",
       "      <th>order_hour_of_day</th>\n",
       "      <th>order_dow</th>\n",
       "      <th>days_since_prior_order</th>\n",
       "      <th>user_reorder_rate</th>\n",
       "      <th>user_order_dt</th>\n",
       "      <th>order_streak</th>\n",
       "      <th>reordered</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>196</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>1.400000</td>\n",
       "      <td>0.653460</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.327370</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.694915</td>\n",
       "      <td>20.259259</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>10258</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>0.574180</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.295700</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.694915</td>\n",
       "      <td>20.259259</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>10326</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.649913</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.276632</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.694915</td>\n",
       "      <td>20.259259</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>12427</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>3.300000</td>\n",
       "      <td>0.574180</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.245536</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.694915</td>\n",
       "      <td>20.259259</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>13032</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>6.333333</td>\n",
       "      <td>0.560922</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.190001</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.694915</td>\n",
       "      <td>20.259259</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>13176</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.649913</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.403225</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.694915</td>\n",
       "      <td>20.259259</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>14084</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0.1</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.669969</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.315376</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.694915</td>\n",
       "      <td>20.259259</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>17122</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.649913</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.220314</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.694915</td>\n",
       "      <td>20.259259</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>25133</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.669969</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.192602</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.694915</td>\n",
       "      <td>20.259259</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>26088</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.2</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>0.574180</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.158341</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.694915</td>\n",
       "      <td>20.259259</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  product_id  user_prod_norders  user_norders  user_prod_rate  \\\n",
       "0        1         196                 10            10             1.0   \n",
       "1        1       10258                  9            10             0.9   \n",
       "2        1       10326                  1            10             0.1   \n",
       "3        1       12427                 10            10             1.0   \n",
       "4        1       13032                  3            10             0.3   \n",
       "5        1       13176                  2            10             0.2   \n",
       "6        1       14084                  1            10             0.1   \n",
       "7        1       17122                  1            10             0.1   \n",
       "8        1       25133                  8            10             0.8   \n",
       "9        1       26088                  2            10             0.2   \n",
       "\n",
       "   baskets_since  baskets_since_1st  basket_pos  dept_reorder_prob  \\\n",
       "0              0                  9    1.400000           0.653460   \n",
       "1              0                  8    3.333333           0.574180   \n",
       "2              5                  5    5.000000           0.649913   \n",
       "3              0                  9    3.300000           0.574180   \n",
       "4              0                  8    6.333333           0.560922   \n",
       "5              5                  8    6.000000           0.649913   \n",
       "6              9                  9    2.000000           0.669969   \n",
       "7              5                  5    6.000000           0.649913   \n",
       "8              0                  7    4.000000           0.669969   \n",
       "9              8                  9    4.500000           0.574180   \n",
       "\n",
       "   department_id  is_organic  reorder_prob  order_hour_of_day  order_dow  \\\n",
       "0              0           0      0.327370                  8          4   \n",
       "1              0           0      0.295700                  8          4   \n",
       "2              1           1      0.276632                  8          4   \n",
       "3              0           0      0.245536                  8          4   \n",
       "4              0           0      0.190001                  8          4   \n",
       "5              1           1      0.403225                  8          4   \n",
       "6              1           1      0.315376                  8          4   \n",
       "7              1           0      0.220314                  8          4   \n",
       "8              1           1      0.192602                  8          4   \n",
       "9              0           0      0.158341                  8          4   \n",
       "\n",
       "   days_since_prior_order  user_reorder_rate  user_order_dt  order_streak  \\\n",
       "0                    14.0           0.694915      20.259259           5.0   \n",
       "1                    14.0           0.694915      20.259259           5.0   \n",
       "2                    14.0           0.694915      20.259259           0.0   \n",
       "3                    14.0           0.694915      20.259259           5.0   \n",
       "4                    14.0           0.694915      20.259259           1.0   \n",
       "5                    14.0           0.694915      20.259259           0.0   \n",
       "6                    14.0           0.694915      20.259259           0.0   \n",
       "7                    14.0           0.694915      20.259259           0.0   \n",
       "8                    14.0           0.694915      20.259259           5.0   \n",
       "9                    14.0           0.694915      20.259259           0.0   \n",
       "\n",
       "   reordered  \n",
       "0        1.0  \n",
       "1        1.0  \n",
       "2        0.0  \n",
       "3        0.0  \n",
       "4        1.0  \n",
       "5        0.0  \n",
       "6        0.0  \n",
       "7        0.0  \n",
       "8        1.0  \n",
       "9        1.0  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Assemble all features together in one table\n",
    "#\n",
    "features = user_prod_norders.merge(\n",
    "    user_norders, on='user_id', how='left'\n",
    "    ).merge(user_prod_rate, on=['user_id', 'product_id'], how='left'\n",
    "    ).merge(baskets_since, on=['user_id', 'product_id'], how='left'\n",
    "    ).merge(baskets_since_1st, on=['user_id', 'product_id'], how='left'\n",
    "    ).merge(baskets_pos, on=['user_id', 'product_id'], how='left'            \n",
    "    ).merge(prod_features, on='product_id', how='left'\n",
    "    ).merge(order_features, on='user_id', how='left'\n",
    "    ).merge(user_reorder_rate, on='user_id', how='left'\n",
    "    ).merge(user_order_dt, on='user_id', how='left'\n",
    "    ).merge(pd.read_csv('order_streaks.csv'), on=['user_id','product_id'], how='left')\n",
    "# need to keep \"product features\" for submission stage\n",
    "    #).merge(user_prod_order_dt, on='user_id', how='left'\n",
    "\n",
    "# Add training data, i.e., whether product was reordered by user\n",
    "features = features.merge(\n",
    "    train[['user_id','product_id','reordered']],\n",
    "    on=['user_id','product_id'], how='left').fillna(0)\n",
    "\n",
    "features.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000 81209 75000 206209\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Establish separate training and validation data\n",
    "#\n",
    "\n",
    "Nval = 50000 # seems like a good number\n",
    "uids = train['user_id'].unique()\n",
    "uids_train = uids[:-Nval]\n",
    "uids_val = uids[-Nval:]\n",
    "\n",
    "feature_list = [\n",
    "    'reorder_prob', # product features\n",
    "    'dept_reorder_prob',\n",
    "    'department_id',\n",
    "    'is_organic',\n",
    "    'user_prod_norders', # user-product features\n",
    "    'user_prod_rate',\n",
    "    'baskets_since',\n",
    "    'baskets_since_1st',\n",
    "    'basket_pos',\n",
    "    'order_dow', # order features\n",
    "    'order_hour_of_day',\n",
    "    'days_since_prior_order',\n",
    "    'user_norders', # user features\n",
    "    'user_reorder_rate',\n",
    "    'user_order_dt',\n",
    "    #'user_prod_order_dt',\n",
    "    'order_streak']\n",
    "\n",
    "#\n",
    "# training\n",
    "#\n",
    "where = features['user_id'].isin(uids_train)\n",
    "X_train = features[where][feature_list].as_matrix()\n",
    "y_train = features[where]['reordered'].as_matrix()\n",
    "\n",
    "#\n",
    "# validation\n",
    "#\n",
    "where = features['user_id'].isin(uids_val)\n",
    "X_val = features[where][feature_list].as_matrix()\n",
    "y_val = features[where]['reordered'].as_matrix()\n",
    "\n",
    "#\n",
    "# test / submission\n",
    "#\n",
    "uids_test = orders[orders['eval_set'] == 'test']['user_id'].unique()\n",
    "where = features['user_id'].isin(uids_test)\n",
    "X_test = features[where][feature_list].as_matrix()\n",
    "\n",
    "print len(uids_val), len(uids_train), len(uids_test), len(orders['user_id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Compute training target(s)\n",
    "#\n",
    "target = train.groupby('user_id'\n",
    "    ).apply(lambda x: set(x[x['reordered'] == True]['product_id'])\n",
    "    ).reset_index(name='target')\n",
    "train_target = target[target['user_id'].isin(uids_train)]\n",
    "train_features = features[features['user_id'].isin(uids_train)]\n",
    "val_target = target[target['user_id'].isin(uids_val)]\n",
    "val_features = features[features['user_id'].isin(uids_val)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=10, max_features=4, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=1000, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=15, n_jobs=4, oob_score=False, random_state=0,\n",
      "            verbose=0, warm_start=False)\n",
      "[  4.56911117e-02   9.53036935e-03   2.74916309e-03   1.54195495e-04\n",
      "   1.28045233e-01   2.12984066e-01   1.85575002e-01   2.18027582e-02\n",
      "   2.98521588e-03   2.19768426e-04   3.97639832e-04   1.63400996e-02\n",
      "   1.26731185e-02   1.39836534e-02   5.67513534e-03   3.41193470e-01]\n",
      "Performance on training set ... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/local/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/ipykernel_launcher.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.195 0.378693715714\n",
      "0.2 0.378177936485\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=10, max_features=6, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=1000, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=15, n_jobs=4, oob_score=False, random_state=0,\n",
      "            verbose=0, warm_start=False)\n",
      "[  5.20018506e-02   6.64961308e-03   1.22216548e-03   1.09506985e-04\n",
      "   7.99708554e-02   3.06104997e-01   1.75367684e-01   2.12090777e-02\n",
      "   2.50393063e-03   1.39110430e-04   4.29305491e-04   1.91449402e-02\n",
      "   6.76756133e-03   1.32954339e-02   2.81667584e-03   3.12267292e-01]\n",
      "Performance on training set ... \n",
      "0.195 0.3795489897\n",
      "0.2 0.379530450826\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=15, max_features=4, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=1000, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=15, n_jobs=4, oob_score=False, random_state=0,\n",
      "            verbose=0, warm_start=False)\n",
      "[ 0.05352     0.01067808  0.0019679   0.00048903  0.11108071  0.19981776\n",
      "  0.16005744  0.02860399  0.00624868  0.00116589  0.00243563  0.02395952\n",
      "  0.01916824  0.02159243  0.01064146  0.34857325]\n",
      "Performance on training set ... \n",
      "0.195 0.384900102732\n",
      "0.2 0.385110980532\n",
      "Performance on validation set ... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/local/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/ipykernel_launcher.py:43: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.195 0.378679031773\n",
      "0.2 0.378719996591\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=15, max_features=6, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=1000, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=15, n_jobs=4, oob_score=False, random_state=0,\n",
      "            verbose=0, warm_start=False)\n",
      "[ 0.05676222  0.00779127  0.00105298  0.00042708  0.06887387  0.29650777\n",
      "  0.16873935  0.02310045  0.00525608  0.00106943  0.00236661  0.02579595\n",
      "  0.00927752  0.02926409  0.00963624  0.29407908]\n",
      "Performance on training set ... \n",
      "0.195 0.385490504234\n",
      "0.2 0.385514606946\n",
      "Performance on validation set ... \n",
      "0.195 0.378228002734\n",
      "0.2 0.378458594657\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=20, max_features=4, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=1000, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=15, n_jobs=4, oob_score=False, random_state=0,\n",
      "            verbose=0, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# try a bunch of hyperparameters\n",
    "#\n",
    "trees = []\n",
    "import itertools\n",
    "for mss, md, mf in itertools.product(\n",
    "    [1000, 1500], \n",
    "    [10, 15, 20], \n",
    "    [4, 6]):\n",
    "    #['gini', 'entropy']):\n",
    "\n",
    "    clf = RandomForestClassifier(\n",
    "        criterion='gini',\n",
    "        n_estimators=15, \n",
    "        random_state=0, \n",
    "        min_samples_split=mss,\n",
    "        max_features=mf,\n",
    "        max_depth=md,\n",
    "        n_jobs=4,\n",
    "        verbose=0)\n",
    "    print clf\n",
    "    clf.fit(X_train, y_train)\n",
    "    trees.append(clf)\n",
    "    #export_graphviz(clf, out_file='tree.dot')\n",
    "    print clf.feature_importances_\n",
    "               \n",
    "    print \"Performance on training set ... \"\n",
    "    pred = clf.predict_proba(X_train)[:, 1]\n",
    "    for p in [0.195, 0.2]: # time and time again, this value wins\n",
    "        train_features['prediction'] = pred > p\n",
    "        out = train_features.groupby('user_id').apply(\n",
    "            lambda x: set(x[x['prediction'] == True]['product_id'])\n",
    "            ).reset_index(name='prediction')\n",
    "        out = out.merge(train_target, on='user_id', how='left')\n",
    "        f1 = f1score(out['prediction'], out['target'])\n",
    "        print p, f1score(out['prediction'], out['target'])\n",
    "    \n",
    "    if f1 < 0.38: continue\n",
    "    print \"Performance on validation set ... \"\n",
    "    pred = clf.predict_proba(X_val)[:, 1]\n",
    "    for p in [0.195, 0.2]:\n",
    "        \n",
    "        val_features['prediction'] = pred > p\n",
    "        out = val_features.groupby('user_id').apply(\n",
    "            lambda x: set(x[x['prediction'] == True]['product_id'])\n",
    "            ).reset_index(name='prediction')\n",
    "        out = out.merge(val_target, on='user_id', how='left')\n",
    "        print p, f1score(out['prediction'], out['target'])\n",
    "        del val_features['prediction']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Let's see how we did\n",
    "#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Optional. Retrain the model with the winning hyperparameters on the entire \n",
    "# training data set. I think this is always a good idea? Can it go wrong?\n",
    "\n",
    "#\n",
    "# This model was somewhat over-fitted on the training data.\n",
    "# But it had a decent validation score. let's give it more data \n",
    "# and hope for the best :/. Nothing else is working ...\n",
    "#\n",
    "clf = RandomForestClassifier(\n",
    "                n_estimators=50, \n",
    "                random_state=0, \n",
    "                min_samples_split=500,\n",
    "                max_features=6,\n",
    "                max_depth=15,\n",
    "                n_jobs=4,\n",
    "                verbose=15)\n",
    "X_all = np.vstack((X_train, X_val))\n",
    "y_all = np.concatenate((y_train, y_val))\n",
    "clf.fit(X_all, y_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the model hasn't changed too much\n",
    "\n",
    "print clf.feature_importances_ \n",
    "#print trees[2].feature_importances_\n",
    "\n",
    "uids = np.concatenate((uids_train, uids_val))\n",
    "\n",
    "where = features['user_id'].isin(uids)\n",
    "X_all = features[where][feature_list].as_matrix()\n",
    "pred = clf.predict_proba(X_all)[:, 1]\n",
    "\n",
    "this_features = features[where]\n",
    "this_features['prediction'] = pred > 0.195\n",
    "\n",
    "out = this_features.groupby('user_id').apply(\n",
    "    lambda x: set(x[x['prediction'] == True]['product_id'])\n",
    "    ).reset_index(name='prediction')\n",
    "out = out.merge(target, on='user_id', how='left')\n",
    "\n",
    "print f1score(out['target'], out['prediction'])\n",
    "#del this_features['prediction']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trees[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Let's make a submission!!\n",
    "#\n",
    "print clf\n",
    "#clf = trees[4]\n",
    "\n",
    "#\n",
    "# generate predictions for test set from model\n",
    "#\n",
    "oid_uid_test = orders[orders['eval_set'] == 'test'][['order_id', 'user_id']]\n",
    "where = features['user_id'].isin(uids_test)\n",
    "test_features = features[where]\n",
    "\n",
    "X_test = test_features[feature_list].as_matrix()\n",
    "pred = clf.predict_proba(X_test)[:, 1] > 0.195\n",
    "\n",
    "test_features.loc[:, 'prediction'] = pred\n",
    "test_features = test_features.merge(oid_uid_test, on='user_id', how='left')\n",
    "out = this_features.groupby('order_id').apply(\n",
    "    lambda x: set(x[x['prediction'] == True]['product_id'])\n",
    "    ).reset_index(name='prediction')\n",
    "\n",
    "out.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Write predictions to disk for submission.\n",
    "#\n",
    "\n",
    "fd = open('submission.csv', 'w')\n",
    "fd.write('order_id,products\\n')\n",
    "\n",
    "for oid, pr in zip(out['order_id'], out['prediction']):\n",
    "    fd.write('%d,' % oid)\n",
    "\n",
    "    if pr:\n",
    "        fd.write(' '.join(map(str, pr)))\n",
    "    else:\n",
    "        fd.write('None')\n",
    "    fd.write('\\n')\n",
    "\n",
    "fd.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#\n",
    "# POST MORTEM: WHAT WENT WRONG?\n",
    "#   what does the misclassified data look like?\n",
    "#   what features could we add to better classify them?\n",
    "#\n",
    "\n",
    "#pred = clf.predict_proba(X_train)[:, 1]\n",
    "#train_features['prediction'] = pred > 0.195\n",
    "#train_features[train_features['prediction'] != train_features['reordered']].head(25)\n",
    "def pd_f1score(x):\n",
    "    # an F1 score routine working with dataframes\n",
    "    pr = set(x[x['prediction'] == True]['product_id'])\n",
    "    ob = set(x[x['reordered'] == 1]['product_id'])\n",
    "    if not pr:\n",
    "        pr = set([None])\n",
    "\n",
    "    if not ob:\n",
    "        ob = set([None])\n",
    "        \n",
    "    precision = len(pr & ob) / float(len(pr))\n",
    "    recall = len(pr & ob) / float(len(ob))\n",
    "\n",
    "    if precision == recall == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return 2 * precision * recall / (precision + recall)\n",
    "    \n",
    "f1scores = train_features.groupby('user_id').apply(pd_f1score).reset_index(name='f1score')\n",
    "f1scores.sort_values('f1score').head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#print prior.groupby('user_id').apply(lambda x: len(set(x['orderf1scores['f1score'].mean()\n",
    "#tmp = train_features[train_features['user_id'] == 30542].head(25)\n",
    "tmp = user_reorder_rate.merge(f1scores, on='user_id')\n",
    "pylab.scatter(tmp['user_reorder_rate'], tmp['f1score'], s=5)\n",
    "pylab.show()\n",
    "#tmp[tmp['prediction'] != tmp['reordered']].head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = train_features.groupby('product_id').apply(\n",
    "    lambda x: pd.Series(\n",
    "        {'false_pos':sum((x['prediction'] == 1) & (x['reordered'] == 0)),\n",
    "         'false_neg':sum((x['prediction'] == 0) & (x['reordered'] == 1)),\n",
    "         'true_pos':sum((x['prediction'] == 1) & (x['reordered'] == 1)),\n",
    "         'true_neg':sum((x['prediction'] == 0) & (x['reordered'] == 0))})\n",
    ").reset_index().merge(pd.read_csv('products.csv'), on='product_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors['recall'] = errors['true_pos'] / 1.0 / (errors['false_neg'] + errors['true_pos'])\n",
    "errors['precision'] = errors['true_pos'] / 1.0 / (errors['false_pos'] + errors['true_pos'])\n",
    "errors['f1score'] = 2 * errors['precision'] * errors['recall'] / (errors['precision'] + errors['recall'])\n",
    "\n",
    "errors[errors['false_pos'] + errors['true_pos'] > 50].sort_values('f1score')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = prior.groupby('product_id').apply(len).reset_index(name='norders')\n",
    "tmp = tmp.merge(errors, on='product_id', how='inner')\n",
    "tmp.sort_values('norders', ascending=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#t = prior.groupby('product_id').apply(len)\n",
    "pylab.hist(t, bins=np.linspace(1, 100, 100))\n",
    "pylab.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the product f1 score is not quite the same as the user f1score\n",
    "print errors['f1score'].mean()\n",
    "\n",
    "# I don't know if one tracks the other ... hopefully\n",
    "\n",
    "# Let's retrain part of the classifier on products we performed poorly\n",
    "# on. Kind of like making a hyper-tree where this is the first split\n",
    "bad_products = errors[errors['f1score'] < 0.4]['product_id']\n",
    "print len(bad_products)\n",
    "\n",
    "# Are there a lot of these? Enough to think it will matter?\n",
    "print len( features[features['product_id'].isin(bad_products)] )\n",
    "print len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Although these are only 1/10th of the product selection, they amount to\n",
    "# almsot 1/3rd of the orders ...\n",
    "retrain_features = train_features[train_features['product_id'].isin(bad_products)]\n",
    "X_retrain = retrain_features[feature_list].as_matrix()\n",
    "y_retrain = retrain_features['reordered'].as_matrix()\n",
    "old_clf = clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrees = []\n",
    "for mss in [500, 1000, 1500]:\n",
    "    for md in [6, 10, 15]:\n",
    "        for mf in [4, 6]:\n",
    "            print mss, md, mf\n",
    "            reclf = RandomForestClassifier(\n",
    "                n_estimators=15, \n",
    "                random_state=0, \n",
    "                min_samples_split=mss,\n",
    "                max_features=mf,\n",
    "                max_depth=md,\n",
    "                n_jobs=4,\n",
    "                verbose=0)\n",
    "            reclf.fit(X_retrain, y_retrain)\n",
    "            retrees.append(reclf)\n",
    "            #export_graphviz(clf, out_file='tree.dot')\n",
    "            print reclf.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute training target(s)\n",
    "\n",
    "# first, deep tree\n",
    "pred = clf.predict_proba(X_train)[:, 1]\n",
    "train_features['prediction'] = pred > 0.195\n",
    "\n",
    "# first, deep tree\n",
    "pred = clf.predict_proba(X_val)[:, 1]\n",
    "val_features['prediction'] = pred > 0.195"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "where_t = train_features['product_id'].isin(bad_products)\n",
    "X_retrain = train_features[where_t][feature_list].as_matrix()\n",
    "where_v = val_features['product_id'].isin(bad_products)\n",
    "X_reval = val_features[where_v][feature_list].as_matrix()\n",
    "\n",
    "print \"Original model:\",\n",
    "f1scores = train_features.groupby('user_id').apply(\n",
    "    pd_f1score).reset_index(name='f1score')\n",
    "print f1scores['f1score'].mean(), \"(training)\"\n",
    "f1scores = val_features.groupby('user_id').apply(\n",
    "    pd_f1score).reset_index(name='f1score')\n",
    "print f1scores['f1score'].mean(), \"(validation)\"\n",
    "print\n",
    "\n",
    "print \"Boosted model:\"\n",
    "\n",
    "for _clf in retrees:\n",
    "    print _clf\n",
    "\n",
    "    _pred = _clf.predict_proba(X_retrain)[:, 1]\n",
    "    for p in [0.195]: # time and time again, this value wins\n",
    "        \n",
    "        train_features.loc[where_t, 'prediction'] = _pred > p\n",
    "        f1scores = train_features.groupby('user_id').apply(\n",
    "            pd_f1score).reset_index(name='f1score')\n",
    "        print f1scores['f1score'].mean(), \"(training)\", \"(training)\"        \n",
    "        \n",
    "        #f1scores = train_features.groupby('user_id').apply(\n",
    "        #    pd_f1score).reset_index(name='f1score')\n",
    "        #print p, f1scores['f1score'].mean()\n",
    "    \n",
    "    print \"Performance on validation set ... \"\n",
    "    _pred = _clf.predict_proba(X_reval)[:, 1]\n",
    "    for p in [0.195]:\n",
    "        \n",
    "        val_features.loc[where_v, 'prediction'] = _pred > p\n",
    "        f1scores = val_features.groupby('user_id').apply(\n",
    "            pd_f1score).reset_index(name='f1score')\n",
    "        print p, f1scores['f1score'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Let's make a submission!!\n",
    "#\n",
    "print clf\n",
    "_clf = trees[1]\n",
    "print _clf\n",
    "\n",
    "#\n",
    "# generate predictions for test set from model\n",
    "#\n",
    "oid_uid_test = orders[orders['eval_set'] == 'test'][['order_id', 'user_id']]\n",
    "where = features['user_id'].isin(uids_test)\n",
    "test_features = features[where]\n",
    "where_p = test_features['product_id'].isin(bad_products)\n",
    "\n",
    "X_test = test_features[feature_list].as_matrix()\n",
    "pred = clf.predict_proba(X_test)[:, 1] > 0.195\n",
    "\n",
    "test_features.loc[:, 'prediction'] = pred\n",
    "\n",
    "X_retest = test_features[where_p][feature_list].as_matrix()\n",
    "_pred = _clf.predict_proba(X_retest)[:, 1] > 0.195\n",
    "test_features.loc[where_p, 'prediction'] = _pred\n",
    "\n",
    "test_features = test_features.merge(oid_uid_test, on='user_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = test_features.groupby('order_id').apply(\n",
    "    lambda x: set(x[x['prediction'] == True]['product_id'])\n",
    "    ).reset_index(name='prediction')\n",
    "\n",
    "out.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Write predictions to disk for submission.\n",
    "#\n",
    "\n",
    "fd = open('submission.csv', 'w')\n",
    "fd.write('order_id,products\\n')\n",
    "\n",
    "for oid, pr in zip(out['order_id'], out['prediction']):\n",
    "    fd.write('%d,' % oid)\n",
    "\n",
    "    if pr:\n",
    "        fd.write(' '.join(map(str, pr)))\n",
    "    else:\n",
    "        fd.write('None')\n",
    "    fd.write('\\n')\n",
    "\n",
    "fd.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
